{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20194998\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['shuffle', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "from keras.callbacks import EarlyStopping\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tuenl.sharepoint.com/sites/gad_cbo/JPC/MC/ESA%20PDEng%20ST%20Project/Forms/AllItems.aspx?viewid=235c9f56%2Db4dc%2D418e%2D8800%2Dd0cde58fff30&id=%2Fsites%2Fgad%5Fcbo%2FJPC%2FMC%2FESA%20PDEng%20ST%20Project%2FModelsAndData%2FAudio%2FDevelopment%2Fdata%2Ftone%5Fcnn%5Fhappy%5Fangry%5Fdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking a directory tree and getting the names and directories of the train and test files \n",
    "mydiclist={}\n",
    "curr_path = os.getcwd()\n",
    "crr_path = Path(curr_path)\n",
    "parent_path = crr_path.parent\n",
    "base_path= str(parent_path)+'\\\\data\\\\tone_cnn_8_emotions_dataset\\\\'\n",
    "for dirpath, dirnames, files in os.walk(base_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.wav'):\n",
    "            mydiclist[file_name]= dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pathlib import Path\n",
    "#curr_path = os.getcwd()\n",
    "#crr_path = Path(curr_path)\n",
    "#parent_path = crr_path.parent\n",
    "#path = str(parent_path) +  '\\\\Actor_01\\\\'\n",
    "#mylist= os.listdir(path)\n",
    "#print(type(mylist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "       \n",
    "# (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).        \n",
    "        \n",
    "feeling_list=[]\n",
    "for key in mydiclist:    \n",
    "    if key[6:-16]=='01':\n",
    "        feeling_list.append('neutral')\n",
    "    if key[6:-16]=='02':\n",
    "        feeling_list.append('calm')\n",
    "    elif key[6:-16]=='03':\n",
    "        feeling_list.append('Happy')\n",
    "    elif key[6:-16]=='04':\n",
    "        feeling_list.append('sad')\n",
    "    elif key[6:-16]=='05':\n",
    "        feeling_list.append('angry')\n",
    "    elif key[6:-16]=='06':\n",
    "        feeling_list.append('fearful')\n",
    "    elif key[6:-16]=='07': \n",
    "        feeling_list.append('disgust')\n",
    "    elif key[6:-16]=='08': \n",
    "        feeling_list.append('surprised')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0       neutral\n",
       "1       neutral\n",
       "2       neutral\n",
       "3       neutral\n",
       "4          calm\n",
       "...         ...\n",
       "1435  surprised\n",
       "1436  surprised\n",
       "1437  surprised\n",
       "1438  surprised\n",
       "1439  surprised\n",
       "\n",
       "[1440 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for key in mydiclist:\n",
    "    X, sample_rate = librosa.load(mydiclist[key]+'\\\\'+key, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=13),\n",
    "                        axis=0)\n",
    "    feature = mfccs\n",
    "    #[float(i) for i in feature]\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark=bookmark+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(columns=['feature'])\n",
    "#bookmark=0\n",
    "#for index,y in enumerate(mylist):\n",
    "#    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "#        X, sample_rate = librosa.load(path+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "#        sample_rate = np.array(sample_rate)\n",
    "#        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "#                                            sr=sample_rate, \n",
    "#                                            n_mfcc=13),\n",
    "#                        axis=0)\n",
    "#        feature = mfccs\n",
    "#        #[float(i) for i in feature]\n",
    "#        df.loc[bookmark] = [feature]\n",
    "#        bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-58.038567</td>\n",
       "      <td>-56.945641</td>\n",
       "      <td>-56.222530</td>\n",
       "      <td>-58.507347</td>\n",
       "      <td>-60.056675</td>\n",
       "      <td>-61.237431</td>\n",
       "      <td>-61.514500</td>\n",
       "      <td>-59.097778</td>\n",
       "      <td>-59.701725</td>\n",
       "      <td>-59.199768</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.093227</td>\n",
       "      <td>-59.682449</td>\n",
       "      <td>-59.239323</td>\n",
       "      <td>-58.234951</td>\n",
       "      <td>-58.351200</td>\n",
       "      <td>-58.628315</td>\n",
       "      <td>-56.472054</td>\n",
       "      <td>-57.995502</td>\n",
       "      <td>-61.422791</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>-41.384239</td>\n",
       "      <td>-41.737446</td>\n",
       "      <td>-41.841331</td>\n",
       "      <td>-41.788242</td>\n",
       "      <td>-41.841331</td>\n",
       "      <td>-41.841331</td>\n",
       "      <td>-41.841331</td>\n",
       "      <td>-41.129440</td>\n",
       "      <td>-39.942932</td>\n",
       "      <td>-40.544277</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.796743</td>\n",
       "      <td>-26.133371</td>\n",
       "      <td>-30.697853</td>\n",
       "      <td>-32.224312</td>\n",
       "      <td>-32.934696</td>\n",
       "      <td>-31.673471</td>\n",
       "      <td>-32.869686</td>\n",
       "      <td>-34.093655</td>\n",
       "      <td>-35.078102</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.444584</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.493233</td>\n",
       "      <td>-52.484932</td>\n",
       "      <td>-52.034988</td>\n",
       "      <td>-51.387383</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>-61.856262</td>\n",
       "      <td>-59.841209</td>\n",
       "      <td>-59.137161</td>\n",
       "      <td>-59.362698</td>\n",
       "      <td>-59.033707</td>\n",
       "      <td>-58.838234</td>\n",
       "      <td>-58.639858</td>\n",
       "      <td>-58.646053</td>\n",
       "      <td>-59.653038</td>\n",
       "      <td>-62.066002</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.521854</td>\n",
       "      <td>-58.689701</td>\n",
       "      <td>-58.885868</td>\n",
       "      <td>-57.405605</td>\n",
       "      <td>-55.915184</td>\n",
       "      <td>-54.769287</td>\n",
       "      <td>-56.704975</td>\n",
       "      <td>-56.083965</td>\n",
       "      <td>-56.884750</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>-49.250637</td>\n",
       "      <td>-47.740860</td>\n",
       "      <td>-49.672993</td>\n",
       "      <td>-50.764851</td>\n",
       "      <td>-51.801365</td>\n",
       "      <td>-51.357605</td>\n",
       "      <td>-51.992981</td>\n",
       "      <td>-51.296574</td>\n",
       "      <td>-49.914944</td>\n",
       "      <td>-51.691490</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.861893</td>\n",
       "      <td>-46.302067</td>\n",
       "      <td>-49.884659</td>\n",
       "      <td>-48.919327</td>\n",
       "      <td>-49.577133</td>\n",
       "      <td>-49.001667</td>\n",
       "      <td>-47.466061</td>\n",
       "      <td>-47.603310</td>\n",
       "      <td>-46.976017</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>-57.354610</td>\n",
       "      <td>-56.764095</td>\n",
       "      <td>-56.161160</td>\n",
       "      <td>-57.752335</td>\n",
       "      <td>-57.455196</td>\n",
       "      <td>-55.104424</td>\n",
       "      <td>-56.519279</td>\n",
       "      <td>-61.743305</td>\n",
       "      <td>-62.724113</td>\n",
       "      <td>-60.338741</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.687904</td>\n",
       "      <td>-62.345596</td>\n",
       "      <td>-59.201382</td>\n",
       "      <td>-57.919853</td>\n",
       "      <td>-57.302345</td>\n",
       "      <td>-57.860756</td>\n",
       "      <td>-59.635963</td>\n",
       "      <td>-59.327217</td>\n",
       "      <td>-62.622055</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.049412</td>\n",
       "      <td>-53.750706</td>\n",
       "      <td>-53.949821</td>\n",
       "      <td>-53.864204</td>\n",
       "      <td>-55.672630</td>\n",
       "      <td>-55.545002</td>\n",
       "      <td>-55.861759</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>-55.912144</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-60.671242</td>\n",
       "      <td>-61.501102</td>\n",
       "      <td>-60.820377</td>\n",
       "      <td>-60.948307</td>\n",
       "      <td>-61.316853</td>\n",
       "      <td>-60.825981</td>\n",
       "      <td>-60.520775</td>\n",
       "      <td>-59.193661</td>\n",
       "      <td>-59.009708</td>\n",
       "      <td>-59.532661</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.707048</td>\n",
       "      <td>-21.717684</td>\n",
       "      <td>-22.771929</td>\n",
       "      <td>-22.873360</td>\n",
       "      <td>-21.651493</td>\n",
       "      <td>-20.168156</td>\n",
       "      <td>-20.363548</td>\n",
       "      <td>-20.848034</td>\n",
       "      <td>-18.700886</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>-49.825691</td>\n",
       "      <td>-49.267822</td>\n",
       "      <td>-49.619240</td>\n",
       "      <td>-50.928787</td>\n",
       "      <td>-51.196487</td>\n",
       "      <td>-50.622883</td>\n",
       "      <td>-51.028446</td>\n",
       "      <td>-50.076561</td>\n",
       "      <td>-50.141853</td>\n",
       "      <td>-51.056152</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.926853</td>\n",
       "      <td>-46.416359</td>\n",
       "      <td>-45.444965</td>\n",
       "      <td>-45.200439</td>\n",
       "      <td>-46.972042</td>\n",
       "      <td>-47.902260</td>\n",
       "      <td>-48.657658</td>\n",
       "      <td>-47.372757</td>\n",
       "      <td>-48.934853</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-55.164009</td>\n",
       "      <td>-55.861851</td>\n",
       "      <td>-56.465736</td>\n",
       "      <td>-55.386902</td>\n",
       "      <td>-55.355251</td>\n",
       "      <td>-55.873501</td>\n",
       "      <td>-56.220478</td>\n",
       "      <td>-54.905071</td>\n",
       "      <td>-54.357304</td>\n",
       "      <td>-52.946331</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.844704</td>\n",
       "      <td>-55.881474</td>\n",
       "      <td>-54.258457</td>\n",
       "      <td>-51.195881</td>\n",
       "      <td>-50.088661</td>\n",
       "      <td>-51.145996</td>\n",
       "      <td>-53.190781</td>\n",
       "      <td>-54.721615</td>\n",
       "      <td>-53.742119</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "302  -58.038567 -56.945641 -56.222530 -58.507347 -60.056675 -61.237431   \n",
       "635  -41.384239 -41.737446 -41.841331 -41.788242 -41.841331 -41.841331   \n",
       "209  -52.493233 -52.493233 -52.493233 -52.493233 -52.493233 -52.493233   \n",
       "604  -61.856262 -59.841209 -59.137161 -59.362698 -59.033707 -58.838234   \n",
       "966  -49.250637 -47.740860 -49.672993 -50.764851 -51.801365 -51.357605   \n",
       "734  -57.354610 -56.764095 -56.161160 -57.752335 -57.455196 -55.104424   \n",
       "793  -55.912144 -55.912144 -55.912144 -55.912144 -55.912144 -55.912144   \n",
       "409  -60.671242 -61.501102 -60.820377 -60.948307 -61.316853 -60.825981   \n",
       "883  -49.825691 -49.267822 -49.619240 -50.928787 -51.196487 -50.622883   \n",
       "1304 -55.164009 -55.861851 -56.465736 -55.386902 -55.355251 -55.873501   \n",
       "\n",
       "            6          7          8          9    ...        207        208  \\\n",
       "302  -61.514500 -59.097778 -59.701725 -59.199768  ... -60.093227 -59.682449   \n",
       "635  -41.841331 -41.129440 -39.942932 -40.544277  ... -24.796743 -26.133371   \n",
       "209  -52.493233 -52.493233 -52.493233 -52.493233  ... -52.493233 -52.493233   \n",
       "604  -58.639858 -58.646053 -59.653038 -62.066002  ... -56.521854 -58.689701   \n",
       "966  -51.992981 -51.296574 -49.914944 -51.691490  ... -45.861893 -46.302067   \n",
       "734  -56.519279 -61.743305 -62.724113 -60.338741  ... -61.687904 -62.345596   \n",
       "793  -55.912144 -55.912144 -55.912144 -55.912144  ... -54.049412 -53.750706   \n",
       "409  -60.520775 -59.193661 -59.009708 -59.532661  ... -21.707048 -21.717684   \n",
       "883  -51.028446 -50.076561 -50.141853 -51.056152  ... -46.926853 -46.416359   \n",
       "1304 -56.220478 -54.905071 -54.357304 -52.946331  ... -51.844704 -55.881474   \n",
       "\n",
       "            209        210        211        212        213        214  \\\n",
       "302  -59.239323 -58.234951 -58.351200 -58.628315 -56.472054 -57.995502   \n",
       "635  -30.697853 -32.224312 -32.934696 -31.673471 -32.869686 -34.093655   \n",
       "209  -52.444584 -52.493233 -52.493233 -52.493233 -52.484932 -52.034988   \n",
       "604  -58.885868 -57.405605 -55.915184 -54.769287 -56.704975 -56.083965   \n",
       "966  -49.884659 -48.919327 -49.577133 -49.001667 -47.466061 -47.603310   \n",
       "734  -59.201382 -57.919853 -57.302345 -57.860756 -59.635963 -59.327217   \n",
       "793  -53.949821 -53.864204 -55.672630 -55.545002 -55.861759 -55.912144   \n",
       "409  -22.771929 -22.873360 -21.651493 -20.168156 -20.363548 -20.848034   \n",
       "883  -45.444965 -45.200439 -46.972042 -47.902260 -48.657658 -47.372757   \n",
       "1304 -54.258457 -51.195881 -50.088661 -51.145996 -53.190781 -54.721615   \n",
       "\n",
       "            215      0    \n",
       "302  -61.422791  neutral  \n",
       "635  -35.078102    angry  \n",
       "209  -51.387383    angry  \n",
       "604  -56.884750     calm  \n",
       "966  -46.976017     calm  \n",
       "734  -62.622055    Happy  \n",
       "793  -55.912144    Happy  \n",
       "409  -18.700886  disgust  \n",
       "883  -48.934853  fearful  \n",
       "1304 -53.742119  disgust  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-63.488754</td>\n",
       "      <td>-60.576641</td>\n",
       "      <td>-56.701763</td>\n",
       "      <td>-56.070492</td>\n",
       "      <td>-58.910580</td>\n",
       "      <td>-61.154972</td>\n",
       "      <td>-59.071247</td>\n",
       "      <td>-56.579098</td>\n",
       "      <td>-55.198971</td>\n",
       "      <td>-56.515549</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.535545</td>\n",
       "      <td>-55.875542</td>\n",
       "      <td>-54.532017</td>\n",
       "      <td>-55.293648</td>\n",
       "      <td>-55.092278</td>\n",
       "      <td>-54.403172</td>\n",
       "      <td>-56.776207</td>\n",
       "      <td>-59.719543</td>\n",
       "      <td>-60.744717</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>-49.626648</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.813663</td>\n",
       "      <td>-44.129826</td>\n",
       "      <td>-46.296909</td>\n",
       "      <td>-47.937187</td>\n",
       "      <td>-48.107651</td>\n",
       "      <td>-47.130939</td>\n",
       "      <td>-49.147984</td>\n",
       "      <td>-49.498745</td>\n",
       "      <td>-48.562721</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-52.358807</td>\n",
       "      <td>-51.610115</td>\n",
       "      <td>-50.046631</td>\n",
       "      <td>-49.424397</td>\n",
       "      <td>-51.406414</td>\n",
       "      <td>-51.462032</td>\n",
       "      <td>-50.192711</td>\n",
       "      <td>-51.117050</td>\n",
       "      <td>-52.238796</td>\n",
       "      <td>-51.404472</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.206566</td>\n",
       "      <td>-49.825951</td>\n",
       "      <td>-48.717484</td>\n",
       "      <td>-47.780880</td>\n",
       "      <td>-49.512329</td>\n",
       "      <td>-49.161598</td>\n",
       "      <td>-46.813667</td>\n",
       "      <td>-46.451687</td>\n",
       "      <td>-45.739906</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.825310</td>\n",
       "      <td>-66.289062</td>\n",
       "      <td>-66.707939</td>\n",
       "      <td>-66.696861</td>\n",
       "      <td>-66.638000</td>\n",
       "      <td>-65.720284</td>\n",
       "      <td>-65.538300</td>\n",
       "      <td>-66.403282</td>\n",
       "      <td>-66.623062</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>-52.084724</td>\n",
       "      <td>-52.463596</td>\n",
       "      <td>-52.680771</td>\n",
       "      <td>-50.508888</td>\n",
       "      <td>-50.079182</td>\n",
       "      <td>-49.545101</td>\n",
       "      <td>-49.456711</td>\n",
       "      <td>-51.206169</td>\n",
       "      <td>-50.610317</td>\n",
       "      <td>-49.752174</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.680771</td>\n",
       "      <td>-51.061298</td>\n",
       "      <td>-50.774620</td>\n",
       "      <td>-51.132248</td>\n",
       "      <td>-49.962582</td>\n",
       "      <td>-50.319702</td>\n",
       "      <td>-51.773911</td>\n",
       "      <td>-52.370956</td>\n",
       "      <td>-51.886013</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.638100</td>\n",
       "      <td>-48.076477</td>\n",
       "      <td>-47.975407</td>\n",
       "      <td>-47.726406</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.005039</td>\n",
       "      <td>-30.143806</td>\n",
       "      <td>-28.844574</td>\n",
       "      <td>-28.764626</td>\n",
       "      <td>-29.490532</td>\n",
       "      <td>-29.049360</td>\n",
       "      <td>-27.577091</td>\n",
       "      <td>-21.164640</td>\n",
       "      <td>-14.801329</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-66.264893</td>\n",
       "      <td>-67.042038</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.741112</td>\n",
       "      <td>-41.120735</td>\n",
       "      <td>-40.283394</td>\n",
       "      <td>-39.689163</td>\n",
       "      <td>-39.673252</td>\n",
       "      <td>-40.182980</td>\n",
       "      <td>-41.530998</td>\n",
       "      <td>-36.970688</td>\n",
       "      <td>-30.308895</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>-60.638588</td>\n",
       "      <td>-60.965298</td>\n",
       "      <td>-62.446186</td>\n",
       "      <td>-64.448090</td>\n",
       "      <td>-66.764763</td>\n",
       "      <td>-67.361618</td>\n",
       "      <td>-67.469635</td>\n",
       "      <td>-66.982574</td>\n",
       "      <td>-66.915482</td>\n",
       "      <td>-67.386955</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.947651</td>\n",
       "      <td>-33.441402</td>\n",
       "      <td>-32.761349</td>\n",
       "      <td>-32.913437</td>\n",
       "      <td>-33.728172</td>\n",
       "      <td>-33.302490</td>\n",
       "      <td>-32.801800</td>\n",
       "      <td>-29.852169</td>\n",
       "      <td>-27.932539</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-65.707649</td>\n",
       "      <td>-65.707649</td>\n",
       "      <td>-63.114719</td>\n",
       "      <td>-61.518997</td>\n",
       "      <td>-61.097141</td>\n",
       "      <td>-63.424599</td>\n",
       "      <td>-63.720066</td>\n",
       "      <td>-56.854614</td>\n",
       "      <td>-55.168972</td>\n",
       "      <td>-54.639999</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.792141</td>\n",
       "      <td>-40.613159</td>\n",
       "      <td>-41.209202</td>\n",
       "      <td>-41.439201</td>\n",
       "      <td>-43.994278</td>\n",
       "      <td>-49.399620</td>\n",
       "      <td>-50.591599</td>\n",
       "      <td>-49.144051</td>\n",
       "      <td>-48.705654</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-60.369045</td>\n",
       "      <td>-60.083717</td>\n",
       "      <td>-60.978924</td>\n",
       "      <td>-60.952457</td>\n",
       "      <td>-60.982483</td>\n",
       "      <td>-60.983948</td>\n",
       "      <td>-60.981255</td>\n",
       "      <td>-60.981255</td>\n",
       "      <td>-60.981255</td>\n",
       "      <td>-60.249615</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.848366</td>\n",
       "      <td>-49.632915</td>\n",
       "      <td>-55.102585</td>\n",
       "      <td>-55.481716</td>\n",
       "      <td>-52.952229</td>\n",
       "      <td>-51.401585</td>\n",
       "      <td>-54.072971</td>\n",
       "      <td>-52.639565</td>\n",
       "      <td>-52.664181</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "314  -63.488754 -60.576641 -56.701763 -56.070492 -58.910580 -61.154972   \n",
       "215  -49.626648 -49.626648 -49.626648 -49.626648 -49.626648 -49.626648   \n",
       "546  -52.358807 -51.610115 -50.046631 -49.424397 -51.406414 -51.462032   \n",
       "1194 -66.638000 -66.638000 -66.638000 -66.638000 -66.638000 -66.638000   \n",
       "657  -52.084724 -52.463596 -52.680771 -50.508888 -50.079182 -49.545101   \n",
       "677  -48.638100 -48.638100 -48.638100 -48.638100 -48.638100 -48.638100   \n",
       "188  -66.264893 -66.264893 -66.264893 -66.264893 -66.264893 -66.264893   \n",
       "370  -60.638588 -60.965298 -62.446186 -64.448090 -66.764763 -67.361618   \n",
       "64   -65.707649 -65.707649 -63.114719 -61.518997 -61.097141 -63.424599   \n",
       "13   -60.369045 -60.083717 -60.978924 -60.952457 -60.982483 -60.983948   \n",
       "\n",
       "            6          7          8          9    ...        207        208  \\\n",
       "314  -59.071247 -56.579098 -55.198971 -56.515549  ... -59.535545 -55.875542   \n",
       "215  -49.626648 -49.626648 -49.626648 -49.626648  ... -41.813663 -44.129826   \n",
       "546  -50.192711 -51.117050 -52.238796 -51.404472  ... -48.206566 -49.825951   \n",
       "1194 -66.638000 -66.638000 -66.638000 -66.638000  ... -64.825310 -66.289062   \n",
       "657  -49.456711 -51.206169 -50.610317 -49.752174  ... -52.680771 -51.061298   \n",
       "677  -48.638100 -48.076477 -47.975407 -47.726406  ... -34.005039 -30.143806   \n",
       "188  -66.264893 -66.264893 -66.264893 -67.042038  ... -40.741112 -41.120735   \n",
       "370  -67.469635 -66.982574 -66.915482 -67.386955  ... -31.947651 -33.441402   \n",
       "64   -63.720066 -56.854614 -55.168972 -54.639999  ... -39.792141 -40.613159   \n",
       "13   -60.981255 -60.981255 -60.981255 -60.249615  ... -49.848366 -49.632915   \n",
       "\n",
       "            209        210        211        212        213        214  \\\n",
       "314  -54.532017 -55.293648 -55.092278 -54.403172 -56.776207 -59.719543   \n",
       "215  -46.296909 -47.937187 -48.107651 -47.130939 -49.147984 -49.498745   \n",
       "546  -48.717484 -47.780880 -49.512329 -49.161598 -46.813667 -46.451687   \n",
       "1194 -66.707939 -66.696861 -66.638000 -65.720284 -65.538300 -66.403282   \n",
       "657  -50.774620 -51.132248 -49.962582 -50.319702 -51.773911 -52.370956   \n",
       "677  -28.844574 -28.764626 -29.490532 -29.049360 -27.577091 -21.164640   \n",
       "188  -40.283394 -39.689163 -39.673252 -40.182980 -41.530998 -36.970688   \n",
       "370  -32.761349 -32.913437 -33.728172 -33.302490 -32.801800 -29.852169   \n",
       "64   -41.209202 -41.439201 -43.994278 -49.399620 -50.591599 -49.144051   \n",
       "13   -55.102585 -55.481716 -52.952229 -51.401585 -54.072971 -52.639565   \n",
       "\n",
       "            215        0    \n",
       "314  -60.744717      Happy  \n",
       "215  -48.562721      angry  \n",
       "546  -45.739906       calm  \n",
       "1194 -66.623062  surprised  \n",
       "657  -51.886013  surprised  \n",
       "677  -14.801329      Happy  \n",
       "188  -30.308895       calm  \n",
       "370  -27.932539       calm  \n",
       "64   -48.705654       calm  \n",
       "13   -52.664181      Happy  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1142, 1)\n"
     ]
    }
   ],
   "source": [
    "trainlabel = train.iloc[:, -1:]\n",
    "print(shape(trainlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['angry']\n",
      " ['angry']\n",
      " ['calm']\n",
      " ...\n",
      " ['neutral']\n",
      " ['fearful']\n",
      " ['calm']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20194998\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "print(y_train)\n",
    "lb = LabelEncoder()\n",
    "\n",
    "nb_classes = 8 \n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train), nb_classes)\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test), nb_classes)\n",
    "\n",
    "numpy.save('encoder.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 216)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#filters, kernel_size, strides=1, padding='valid', data_format='channels_last',\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same', input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax')) #softmax as we are doing multiclass classification\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 27656     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 357,256\n",
      "Trainable params: 357,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\n",
    "             'categorical_crossentropy', \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "#tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es = EarlyStopping(monitor='loss', mode='min')\n",
    "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=200, validation_data=(x_testcnn, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 7s 103ms/step - loss: 2.1563 - accuracy: 0.1349 - val_loss: 2.0799 - val_accuracy: 0.1208\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 7s 96ms/step - loss: 2.0627 - accuracy: 0.1646 - val_loss: 2.0453 - val_accuracy: 0.1846\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 2.0382 - accuracy: 0.1970 - val_loss: 2.0162 - val_accuracy: 0.1544\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 2.0013 - accuracy: 0.2277 - val_loss: 1.9953 - val_accuracy: 0.2450\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 7s 101ms/step - loss: 1.9748 - accuracy: 0.2417 - val_loss: 1.9334 - val_accuracy: 0.2886\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 9s 121ms/step - loss: 1.9139 - accuracy: 0.2723 - val_loss: 1.9101 - val_accuracy: 0.2584\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 10s 133ms/step - loss: 1.8996 - accuracy: 0.2837 - val_loss: 1.9099 - val_accuracy: 0.2617\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 1.8373 - accuracy: 0.3074 - val_loss: 1.9375 - val_accuracy: 0.2483\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 8s 112ms/step - loss: 1.7952 - accuracy: 0.3214 - val_loss: 1.7249 - val_accuracy: 0.3289\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 6s 88ms/step - loss: 1.7909 - accuracy: 0.3091 - val_loss: 1.7306 - val_accuracy: 0.3490\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 1.7095 - accuracy: 0.3222 - val_loss: 1.7282 - val_accuracy: 0.3624\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 7s 98ms/step - loss: 1.6848 - accuracy: 0.3634 - val_loss: 1.7314 - val_accuracy: 0.3121\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 6s 88ms/step - loss: 1.6339 - accuracy: 0.3678 - val_loss: 1.6637 - val_accuracy: 0.3557\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 1.6319 - accuracy: 0.3932 - val_loss: 1.7524 - val_accuracy: 0.3087\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 1.5857 - accuracy: 0.4028 - val_loss: 1.6812 - val_accuracy: 0.3658\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 1.5707 - accuracy: 0.4177 - val_loss: 1.6860 - val_accuracy: 0.3356\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 6s 88ms/step - loss: 1.5703 - accuracy: 0.4028 - val_loss: 1.6274 - val_accuracy: 0.3490\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 7s 98ms/step - loss: 1.5005 - accuracy: 0.4335 - val_loss: 1.6207 - val_accuracy: 0.3758\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 8s 113ms/step - loss: 1.4792 - accuracy: 0.4378 - val_loss: 1.6942 - val_accuracy: 0.3356\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 1.4701 - accuracy: 0.4536 - val_loss: 1.7099 - val_accuracy: 0.3356\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 8s 107ms/step - loss: 1.4602 - accuracy: 0.4483 - val_loss: 1.6065 - val_accuracy: 0.3456\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 1.4260 - accuracy: 0.4772 - val_loss: 1.6310 - val_accuracy: 0.3624\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 1.3740 - accuracy: 0.4799 - val_loss: 1.6257 - val_accuracy: 0.3423\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 1.3431 - accuracy: 0.5044 - val_loss: 1.5886 - val_accuracy: 0.3456\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 1.3396 - accuracy: 0.5053 - val_loss: 1.6484 - val_accuracy: 0.3557\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 1.3161 - accuracy: 0.5175 - val_loss: 1.7091 - val_accuracy: 0.3490\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 7s 97ms/step - loss: 1.2902 - accuracy: 0.5368 - val_loss: 1.6585 - val_accuracy: 0.3557\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 1.2874 - accuracy: 0.5271 - val_loss: 1.6608 - val_accuracy: 0.3591\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 7s 99ms/step - loss: 1.2186 - accuracy: 0.5420 - val_loss: 1.5985 - val_accuracy: 0.3691\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 1.1909 - accuracy: 0.5648 - val_loss: 1.5837 - val_accuracy: 0.3658\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 1.1477 - accuracy: 0.5841 - val_loss: 1.6526 - val_accuracy: 0.3826\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 1.1092 - accuracy: 0.6103 - val_loss: 1.6386 - val_accuracy: 0.3758\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 9s 132ms/step - loss: 1.0842 - accuracy: 0.6252 - val_loss: 1.6132 - val_accuracy: 0.4195\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 7s 91ms/step - loss: 1.1083 - accuracy: 0.6068 - val_loss: 1.6251 - val_accuracy: 0.3926\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.9999 - accuracy: 0.6567 - val_loss: 1.6139 - val_accuracy: 0.3859\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.9543 - accuracy: 0.6743 - val_loss: 1.6726 - val_accuracy: 0.3893\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.9415 - accuracy: 0.6804 - val_loss: 1.6980 - val_accuracy: 0.3893\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.9039 - accuracy: 0.6900 - val_loss: 1.7289 - val_accuracy: 0.4094\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.8658 - accuracy: 0.6979 - val_loss: 1.7176 - val_accuracy: 0.3893\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.8310 - accuracy: 0.7145 - val_loss: 1.7152 - val_accuracy: 0.4060\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.7749 - accuracy: 0.7469 - val_loss: 1.7053 - val_accuracy: 0.4128\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 7s 96ms/step - loss: 0.7534 - accuracy: 0.7487 - val_loss: 1.7356 - val_accuracy: 0.4060\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.6981 - accuracy: 0.7644 - val_loss: 1.8409 - val_accuracy: 0.3960\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 8s 116ms/step - loss: 0.6694 - accuracy: 0.7706 - val_loss: 1.8581 - val_accuracy: 0.3893\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 0.6213 - accuracy: 0.8065 - val_loss: 1.7790 - val_accuracy: 0.4161\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 7s 95ms/step - loss: 0.6159 - accuracy: 0.7951 - val_loss: 1.8000 - val_accuracy: 0.4329\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.5465 - accuracy: 0.8345 - val_loss: 1.8802 - val_accuracy: 0.3960\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.5555 - accuracy: 0.8266 - val_loss: 1.8591 - val_accuracy: 0.3960\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.4727 - accuracy: 0.8651 - val_loss: 2.0026 - val_accuracy: 0.4094\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 6s 77ms/step - loss: 0.4328 - accuracy: 0.8783 - val_loss: 2.0031 - val_accuracy: 0.3691\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.4294 - accuracy: 0.8835 - val_loss: 1.9597 - val_accuracy: 0.4228\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.3892 - accuracy: 0.8914 - val_loss: 2.0681 - val_accuracy: 0.4161\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.3608 - accuracy: 0.9011 - val_loss: 2.0018 - val_accuracy: 0.4195\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 0.3564 - accuracy: 0.9054 - val_loss: 2.1222 - val_accuracy: 0.4329\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 7s 101ms/step - loss: 0.3115 - accuracy: 0.9186 - val_loss: 2.1916 - val_accuracy: 0.4228\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 9s 120ms/step - loss: 0.2911 - accuracy: 0.9177 - val_loss: 2.3150 - val_accuracy: 0.4161\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 9s 121ms/step - loss: 0.2411 - accuracy: 0.9466 - val_loss: 2.2366 - val_accuracy: 0.4228\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 8s 106ms/step - loss: 0.2277 - accuracy: 0.9422 - val_loss: 2.3300 - val_accuracy: 0.4161\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2330 - accuracy: 0.9378 - val_loss: 2.4540 - val_accuracy: 0.4128\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.1824 - accuracy: 0.9597 - val_loss: 2.3665 - val_accuracy: 0.4362\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.1854 - accuracy: 0.9545 - val_loss: 2.4461 - val_accuracy: 0.4195\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.1472 - accuracy: 0.9702 - val_loss: 2.4600 - val_accuracy: 0.3960\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.1640 - accuracy: 0.9658 - val_loss: 2.6525 - val_accuracy: 0.4262\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.1300 - accuracy: 0.9816 - val_loss: 2.6015 - val_accuracy: 0.4060\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.1147 - accuracy: 0.9851 - val_loss: 2.5851 - val_accuracy: 0.4295\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.1019 - accuracy: 0.9842 - val_loss: 2.5484 - val_accuracy: 0.4262\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 7s 96ms/step - loss: 0.0915 - accuracy: 0.9860 - val_loss: 2.8370 - val_accuracy: 0.4027\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 8s 105ms/step - loss: 0.0888 - accuracy: 0.9851 - val_loss: 2.9059 - val_accuracy: 0.4195\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 9s 119ms/step - loss: 0.0726 - accuracy: 0.9921 - val_loss: 2.7654 - val_accuracy: 0.4295\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 8s 116ms/step - loss: 0.0565 - accuracy: 0.9965 - val_loss: 3.1800 - val_accuracy: 0.4094\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0720 - accuracy: 0.9904 - val_loss: 2.9180 - val_accuracy: 0.4295\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.0456 - accuracy: 0.9974 - val_loss: 2.9443 - val_accuracy: 0.4329\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.0410 - accuracy: 0.9982 - val_loss: 2.9209 - val_accuracy: 0.4262\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.0340 - accuracy: 0.9982 - val_loss: 3.1413 - val_accuracy: 0.4128\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.0285 - accuracy: 0.9991 - val_loss: 3.1058 - val_accuracy: 0.4362\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 3.1847 - val_accuracy: 0.4262\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 3.1985 - val_accuracy: 0.4228\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 3.2558 - val_accuracy: 0.4463\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 3.2686 - val_accuracy: 0.4262\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 3.2705 - val_accuracy: 0.4195\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 8s 107ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 3.3398 - val_accuracy: 0.4362\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 8s 114ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 3.3429 - val_accuracy: 0.4329\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 8s 114ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 3.4214 - val_accuracy: 0.4362\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 7s 103ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 3.3623 - val_accuracy: 0.4329\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 7s 94ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.3643 - val_accuracy: 0.4362\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.5411 - val_accuracy: 0.4463\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.5375 - val_accuracy: 0.4329\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 6s 76ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.5990 - val_accuracy: 0.4295\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.5223 - val_accuracy: 0.4497\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.6940 - val_accuracy: 0.4430\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.7178 - val_accuracy: 0.4329\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.7059 - val_accuracy: 0.4430\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.7241 - val_accuracy: 0.4329\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 8s 117ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.7322 - val_accuracy: 0.4396\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 9s 132ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.7588 - val_accuracy: 0.4430\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 9s 119ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.7931 - val_accuracy: 0.4362\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 7s 96ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.8621 - val_accuracy: 0.4396\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 7s 94ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.7993 - val_accuracy: 0.4430\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.8644 - val_accuracy: 0.4396\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.9406 - val_accuracy: 0.4396\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=100, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zV9fX48dfJTkhCyADCCCBLhmwRRCriYimuOkFqW3FWrdWqbW1r++tXa5dbxI0DREVBBQcIOFgCIhvZEjbBBEJ27vn98b5ICAESyM0nufc8H488cu9n3fNhfM59b1FVjDHGhK4wrwMwxhjjLUsExhgT4iwRGGNMiLNEYIwxIc4SgTHGhDhLBMYYE+IsERhTSSLyioj8v0oeu0lEzjvZ6xhTEywRGGNMiLNEYIwxIc4SgQkq/iqZe0VkqYgcEJEXRaSRiEwTkf0iMl1EGpQ5/mIRWSEi2SIyS0Q6lNnXXUQW+897C4gp91nDRGSJ/9w5ItLlBGO+UUTWicheEZkiIk3820VE/iciu0Qkx39Pnf37hojISn9sW0XknhP6AzMGSwQmOF0OnA+0Ay4CpgF/AFJx/+bvABCRdsB44C4gDZgKfCAiUSISBbwPvAYkA2/7r4v/3B7AS8BNQArwHDBFRKKrEqiIDAQeBq4E0oHNwAT/7guAn/nvIwm4Csjy73sRuElVE4DOwOdV+VxjyrJEYILRk6q6U1W3Al8C81X1W1UtBN4DuvuPuwr4SFU/U9Vi4N9ALHAm0AeIBB5T1WJVfQf4psxn3Ag8p6rzVbVUVV8FCv3nVcV1wEuqutgf3wNAXxFpCRQDCcCpgKjqKlXd7j+vGOgoIomq+qOqLq7i5xrzE0sEJhjtLPM6v4L38f7XTXDfwAFQVR+wBWjq37dVD5+VcXOZ1y2A3/mrhbJFJBto7j+vKsrHkIv71t9UVT8HngKeBnaKyFgRSfQfejkwBNgsIrNFpG8VP9eYn1giMKFsG+6BDrg6edzDfCuwHWjq33ZQRpnXW4B/qGpSmZ84VR1/kjHUw1U1bQVQ1SdUtSfQCVdFdK9/+zeqOhxoiKvCmljFzzXmJ5YITCibCAwVkXNFJBL4Ha56Zw4wFygB7hCRCBG5DOhd5tzngZtF5Ax/o249ERkqIglVjOFN4AYR6eZvX/g/XFXWJhE53X/9SOAAUACU+tswrhOR+v4qrX1A6Un8OZgQZ4nAhCxVXQOMAJ4E9uAali9S1SJVLQIuA34B/IhrT5hU5tyFuHaCp/z71/mPrWoMM4AHgXdxpZDWwNX+3Ym4hPMjrvooC9eOATAS2CQi+4Cb/fdhzAkRW5jGGGNCm5UIjDEmxFkiMMaYEGeJwBhjQpwlAmOMCXERXgdQVampqdqyZUuvwzDGmDpl0aJFe1Q1raJ9dS4RtGzZkoULF3odhjHG1Ckisvlo+6xqyBhjQpwlAmOMCXEBTwQiEi4i34rIhxXsExF5wj8X+1L/1L7GGGNqUE20EdwJrMINly9vMNDW/3MG8Kz/d5UUFxeTmZlJQUHBycRZJ8TExNCsWTMiIyO9DsUYEyQCmghEpBkwFPgHcHcFhwwHxvmn+p0nIkkikl5mzvVKyczMJCEhgZYtW3L4ZJHBRVXJysoiMzOTVq1aeR2OMSZIBLpq6DHg94DvKPub4qbzPSjTv+0wIjJaRBaKyMLdu3cfcZGCggJSUlKCOgkAiAgpKSkhUfIxxtScgCUCERkG7FLVRcc6rIJtR8yCp6pjVbWXqvZKS6uwG2zQJ4GDQuU+jTE1J5Algn7AxSKyCbcG60AReb3cMZm4hUAOaoZbqMMYY0xZsx6B7UsDcumAJQJVfUBVm6lqS9z86p+ravk506cA1/t7D/UBcqraPlAbZGdn88wzz1T5vCFDhpCdnR2AiIwxQWXRKzDrYVj5fkAuX+PjCETkZhG52f92KrABt6jH88CtNR1PdThaIigtPfaiUVOnTiUpKSlQYRljgsGWBfDRPdB6IJzzx4B8RI1MMaGqs4BZ/tdjymxX4LaaiCGQ7r//ftavX0+3bt2IjIwkPj6e9PR0lixZwsqVK7nkkkvYsmULBQUF3HnnnYwePRo4NF1Gbm4ugwcP5qyzzmLOnDk0bdqUyZMnExsb6/GdGWM8tW87vDUS6jeDy1+EsPCAfEydm2voeB76YAUrt+2r1mt2bJLIXy7qdNT9jzzyCMuXL2fJkiXMmjWLoUOHsnz58p+6eL700kskJyeTn5/P6aefzuWXX05KSsph11i7di3jx4/n+eef58orr+Tdd99lxAhbfdCYoFeYC9+8AF2vgYRGh7YX5cHEkVC4H0a+B3HJAQvBppgIgN69ex/Wz/+JJ56ga9eu9OnThy1btrB27dojzmnVqhXdunUDoGfPnmzatKmmwjXGeKW0GN4eBdP/AuMuhlx/9/iSIpcEMhfCpWOgUceAhhF0JYJjfXOvKfXq1fvp9axZs5g+fTpz584lLi6OAQMGVDgOIDo6+qfX4eHh5Ofn10isxhiPqMIHd8G66XDGLa5BeNxwuH4yTL3Hbb/oCeh4ccBDCbpE4IWEhAT2799f4b6cnBwaNGhAXFwcq1evZt68eTUcnTGmVpr1MCx5Hc6+D875A7S7EN68Cp7sAYX74IJ/QM9RNRKKJYJqkJKSQr9+/ejcuTOxsbE0anSonm/QoEGMGTOGLl260L59e/r06eNhpMYYz+3dCNP/6rqCdh8BAx5w21ufA1e/CROvh7PvhzNvr7GQxHXcqTt69eql5RemWbVqFR06dPAoopoXavdrTFDI3Q1zHof5z0FYBPS7E/r/DsLLTSBZWnzktmogIotUtVdF+6xEYIwxgaIKO5bB/DGw7G33kO92HQz8EySmV3xOAJLA8VgiMMaYE5G1HvZtg0adDnXt3LMOvv8YtsyDHzfBj5tdfX9kHPS4HnrfBGntPA27IpYIjDGmsorzYcX78O1rsPnrQ9vrZ7jBXj9udO+TW0NKG8g4E9LaQ+fLILaBNzFXgiUCY4yprEk3wqoPoEErOPfPkN4VdiyH7d+5JNH3Ntf7JynD60irxBKBMcZURu4uWP2R6/M/6GE4OCV8m/O8jasa2MhiY4ypjOWTQH3Q8xeHkkCQsERQDU50GmqAxx57jLy8vGqOyBhT7ZZNhManQcNTvY6k2lkiqAaWCIwJMjuWu5k/D8paD1sXwWlXehdTAFkbQTUoOw31+eefT8OGDZk4cSKFhYVceumlPPTQQxw4cIArr7ySzMxMSktLefDBB9m5cyfbtm3jnHPOITU1lZkzZ3p9K8aY1R+50b2JTWH0LNc1dOlEQOC0KzwOLjCCLxFMu98N4KhOjU+DwY8cdXfZaag//fRT3nnnHRYsWICqcvHFF/PFF1+we/dumjRpwkcffQS4OYjq16/Pf//7X2bOnElqamr1xmyMqbo102DiKEhtD1lr4Z1fwnXvuGqhVv0hsYnXEQZEwBKBiMQAXwDR/s95R1X/Uu6YAcBkwN/5lkmq+rdAxVQTPv30Uz799FO6d+8OQG5uLmvXrqV///7cc8893HfffQwbNoz+/ft7HKkxhpVT4MAuiK4PhTnui2Tj09z8/ysnwwd3wIRrYe8GOOtur6MNmECWCAqBgaqaKyKRwFciMk1Vy0+/+aWqDqu2Tz3GN/eaoKo88MAD3HTTTUfsW7RoEVOnTuWBBx7gggsu4M9//rMHERpjADf528SRh29r0t0lgdgkN/Pn9iWw8CUIj66R6aC9ErBE4F+GMtf/NtL/U7dmuKukstNQX3jhhTz44INcd911xMfHs3XrViIjIykpKSE5OZkRI0YQHx/PK6+8cti5VjVkTA1bMcn9Hj0bouq5lcAadYKIQ2uDMOifrtE4uRXE1PcmzhoQ0DYCEQkHFgFtgKdVdX4Fh/UVke+AbcA9qrqiguuMBkYDZGTUvhF7ZaehHjx4MNdeey19+/YFID4+ntdff51169Zx7733EhYWRmRkJM8++ywAo0ePZvDgwaSnp1tjsTE1adm70PwMaNLt6MdERMG1E2ouJo/UyDTUIpIEvAf8RlWXl9meCPj81UdDgMdVte2xrmXTUIfe/RpT7Xatgmf6wOB/wRmjvY6mRhxrGuoaGUegqtnALGBQue37VDXX/3oqECkiVkdijAms5e+ChEGnS7yOpFYIWCIQkTR/SQARiQXOA1aXO6axiBurLSK9/fFkBSomY0yIKClyU0IUVTBYUxWWvQOtfgbxDWs+tlookG0E6cCr/naCMGCiqn4oIjcDqOoY4ArgFhEpAfKBq/UE66pUFQmy+T8qUtdWlDPGEx/f53r7tOgH174F0QmH9m1b7KaL7v877+KrZQLZa2gp0L2C7WPKvH4KeOpkPysmJoasrCxSUlKCOhmoKllZWcTExHgdijG115LxLgm0Phc2zILXLnWDwmKT3P7lkyAsEjpUX6/1ui4oRhY3a9aMzMxMdu/e7XUoARcTE0OzZs28DsOY2mn7UvjwLmjZH66dCN9Pg7dvgFcvgnaDoKQAvpsAbc+v1QvF1LSgSASRkZG0atXK6zCMMTWtuMA97PP2QlGuKwnEJsMVL0F4BHS4CK5+E979FXzxL4iIcWMGTv+V15HXKkGRCIwxIai0xE0Ot/aTQ9tikuC6tw9vBG53Ady32a0hEMRVxyfDEoExpu5RhY/udklg0CPQ8RKIjofIehBWQWfIiraZn1giMMbUPV/8Cxa/6nr+9LnF62jqPEsExpjaqbQEtn3rFoTZttgtDlNSCCX5kLUOul4DAx/0OsqgYInAGFP75GfD+Kvhh7nufUI6pLWH+EZuUriOw+Hs+63Ov5pYIjDG1C65u+H1S2HXahj6X2g/OGgXhKktLBEYY2oHVdi10vUEytnqZv1sc57XUYUESwTGmBOzdRE06XHy1TNrPnYNv1vmQ16WWy3s+vcho0/1xGmOyxKBMabqti2B5wfCla+d3MpdWxbAWyMgobEb+du8N7Q5H+o3rb5YzXFZIjDGVN2uVe73pq8qnwh2LIOoeLfaF7i2gImj3EN/9Cyb8sFDlgiMMVWXtc79Ptir53hKiuDlIVCc7/r9978b3v0l5O+FX31mScBjlgiMMVV3MBHsXA4F+yAm8djHZy6Awn3QvA/MeQIWjHUTwA1/GtK7BD5ec0w27toYU3VZ6yE6EdQHmd8c//h1MyAsws0DdOPnbq3gM++A7iMCH6s5LksExpiqUYW9692gLglzvX2OZ910aNbblRya9oRRU+CCvwc+VlMpgVyqMkZEFojIdyKyQkQequAYEZEnRGSdiCwVkR6BiscYU032b4fiPGjSDRp1Pn47Qe4u2LEU2gysmfhMlQWyRFAIDFTVrkA3YJCIlO8YPBho6/8ZDTwbwHiMMdXhYPtAShvI6AuZC6G0+OjHr5/pfrc+N/CxmRMSsESgTq7/baT/p/yCu8OBcf5j5wFJIpIeqJiMMdXgsETQx5UOdiw9+vHrZ0BcCqR3q5n4TJUFtI1ARMJFZAmwC/hMVctXJjYFtpR5n+nfVv46o0VkoYgsDIXlKI2p1bLWQ0QsJDQ5NPr3h3kVH+vzwfrPofVAWxOgFgvo34yqlqpqN6AZ0FtEOpc7pKKx6eVLDajqWFXtpaq90tLSAhGqMaaystZBSmv3YE9sAkktjt5OsHMZHNht1UK1XI2kaFXNBmYBg8rtygSal3nfDNhWEzEZY05Q1npIPuXQ+4w+8MN815voQJZbN3jzHPd+3Qx3TGtrKK7NAjagTETSgGJVzRaRWOA84J/lDpsC3C4iE4AzgBxV3R6omIwxJ6m0BH7c6BaFPyijDyx9C97+BayZBqWFbnvyKeArhUanQUIjT8I1lRPIEkE6MFNElgLf4NoIPhSRm0XkZv8xU4ENwDrgeeDWAMZjjKmq/TtgwfMuAQBkbwZfiWsoPqjFWe732k+h+3UwejZcMsa1IWRvhlOH1nzcpkoCViJQ1aVA9wq2jynzWoHbAhWDMeYk5GfDa5e6NQJi6kOXK121EByeCNLawa9nuHaDg3MGNekG3a5xE8vFJtV87KZKrBnfGHOkkkI3PfSe7yG+Mcx7xtX5/9R1tPXhxzfrVfHEcfFpEB4Z+HjNSbFJ54wxh/P54P1bYNOXcOlYN1nc1Hvc2gF717vSQVyK11GaamQlAmPM4ZZOgOXvwnl/ha5XQddr3MN//rP+rqNtbNH4IGOJwBhzuE1fQVwq9LvLvY+Ohx6jYOUU2Pbt4e0DJihYIjDGHC5zoavzL/utv/eNgEJBDiS3Puqppm6yRGCMOaQgxzUQN+15+PakjENjB8o3FJs6zxKBMeaQbUsAhaYVzAh/1m8hsSk0O73GwzKBZb2GjDGHbF3kfjepIBE06Q53r6zZeEyNsBKBMeaQrYtcG0BcsteRmBpkicAYc8jWRUe2D5igZ4nAGOPs2+aWoWzWy+tITA2zRGBMsJv7NHxwFxTlHfu4zIXut5UIQo41FhsTzEqLYfajUJAN2xbD1eOh/hGLADpbF0FYpFuQ3oQUKxEYE8w2f+2SQO/RkLUBnj8HNsxy6wSUt3URNO4MkTE1HqbxliUCY4LZqg8gMg7Oewh+/RlExMC44fCv1jDxelj6tptkzlfqpo9oau0DociqhowJVj4frP4I2pwLUXHQsAPc/BV8/wlsmAnrZ8LKyTB/DJz+ayjKtfaBEBWwEoGINBeRmSKySkRWiMidFRwzQERyRGSJ/+fPgYrHmJCzdZHrBXRqmWUlYxKhy8/hkmfc4LBLn4PsH+B9/6KBlghCUiBLBCXA71R1sYgkAItE5DNVLT808UtVHRbAOIwJTas/gLAIaHdhxftFoOvV0H4wzHoE9m60mUVDVCCXqtwObPe/3i8iq4CmgI1RNybQVF37QKufHX+pyJj6MOjhmonL1Eo10lgsIi1x6xfPr2B3XxH5TkSmiUinmojHmKC3axXs3XBoxlBjjiHgjcUiEg+8C9ylqvvK7V4MtFDVXBEZArwPtK3gGqOB0QAZGRkBjtiYILByMiDQfqjXkZg6IKAlAhGJxCWBN1R1Uvn9qrpPVXP9r6cCkSKSWsFxY1W1l6r2SktLC2TIxtRuxQUw/lpY8f6R+77/BCaNhse7wuxHoMWZkNCo5mM0dU7ASgQiIsCLwCpV/e9RjmkM7FRVFZHeuMSUFaiYjKnzvn0N1nwEG2dDehdIPsVt3zALxl/tlpjM6OO6g552paehmrojkFVD/YCRwDIRWeLf9gcgA0BVxwBXALeISAmQD1ytqhrAmIypu0oK4av/QaPTXJfPSTfBDdPgwC5451eQ0hZu/NytMWxMFQSy19BXgBznmKeApwIVgzFBZckbsG8rXPwk5O2FSb+GLx6FDbOhOB+ues2SgDkhNrLYmLqgpAi+/K+bAqL1QDcG4PtpMPufbv/lL0Jae29jNHWWJQJj6oLvxkPOFhj2P5cEAIb+B3auhHYXwGlXeBufqdMsERhT25UUwZf/cWsGtznv0PbYBnDr3EOJwZgTZLOPGlNb7FkHLw06tID8QV/+G7I3w8A/HfnQtyRgqoElAmNqi1n/Bz/MhbdGwoE9btuO5a400OWqw0sDxlQjSwTG1Aa718DySXDqMJcE3rnBdRedfKurAhr0iNcRmiBmbQTG1AZf/AsiY+Gix+H7j2HybTD2HNi1Aq4cB3HJXkdogpiVCIzx2p61sPxdNxq4Xip0HwE9f+GSQIeLoeNwryM0Qc5KBMZ47Yt/uyUkz7zj0LbBj0Lj06DTZd7FZUKGJQJjvLRrFSybCH1uhfgyEypGRLsSgjE1IKSqhnILS7wOwZhD9u+EN6+EuBTod8RKrsbUmJBJBNOWbefMh2ewcc8Br0MxBgpz4c2fux5C106E+IZeR2RCWMgkgh4tGqDAfe8uxeezCU6Nh0qL4e1RbozAz1+Fpj28jsiEuJBJBI0SY/jT0A4s2LiXNxb84HU4JpTNfRrWTYdh/3XzBBnjsZBJBPh8XNmygLPapPLI1FVk/pjndUQmFBXsg68fg7YXuC6ixtQClUoEInKniCSK86KILBaRuvVVZvk7yDNnMCbpNZLJ5g/vLafUqohMIGX/cOSSkvOfg/wfYcAD3sRkTAUqWyL4pX/h+QuANOAGoG6NeW9zHvQeTfzK8cyIvJtO61/kgn9O48kZa9m5r8Dr6Eyw8flg4ijXFvDVY25bfjbMfRLaD7F2AVOrVDYRHJzicAjwsqp+x3FWHxOR5iIyU0RWicgKETmif5y/hPGEiKwTkaUiErj/HXHJMPifcOs8Itv8jPsiJ/B+8U0Ufv5PBj0yhYc+WMG+guKAfbwJMcvfgW2LIa0DTP8LLHoV5j0LBTkw4H6vozPmMFKZJYJF5GWgKdAK6AqEA7NUtecxzkkH0lV1sYgkAIuAS1R1ZZljhgC/wSWYM4DHVfWMY8XSq1cvXbhw4XFjPq4f5rtZHdd+QmFYLFOKT+fLqJ9x7pCfc3GPFohN72uOJW8vZK0HFNQHDVpBQiO3rygPnuoF9dLgV5/ChGth/edu9HCbc+Gq1z0N3YQmEVmkqr0q3FfJRBAGdAM2qGq2iCQDzVR1aRWCmAw8paqfldn2HC6hjPe/XwMMUNXtR7tOtSWCg7YvhfljKF0xhfDi/WRpAo/H3k7bAddweY+mxEXZ4GtTjiqMPRu2f3doW2Q9GPwIdB/pJpCb+Q+3sHyLM6HoAIy7BDK/gVu+hkadvIvdhKzqSAT9gCWqekBERgA9cN/eN1cygJbAF0Bnf1vDwe0fAo/4F7pHRGYA96nqwnLnjwZGA2RkZPTcvLlSH1s1xQWUrpvOvo//j4Sc1dxSdCfzo/rw90s6M7xb0+r/PFN3bfoaXhkC/X8HLfq5xDDncdj4hav/3zDb/83/tUPnFB2AHzdZEjCeOVYiqGwbwbNAnoh0BX4PbAbGVfLD44F3gbvKJoGDuys45YjMpKpjVbWXqvZKS0ur4JRqEBlDeIdhNLhlGuFNu/FczJNck7SC3761hPe+zQzMZ5q6acFzEJME/e9xD/y258HIyXD+32HtZ+ArhvMfOvycqHqWBEytVdlEUKKu6DAcVxJ4HEg43kkiEolLAm+o6qQKDskEmpd53wzYVsmYAiOmPjJiEmGNO3P//od5NHUa/5k4nUmLyyWDkiJY8iaMHQCf/8OTUI0HcjJh1YfQ43qIiju0PSwM+t0BN38JI9+H5FO8i9GYKqpsBfh+EXkAGAn0F5FwIPJYJ4hrbX0RWKWq/z3KYVOA20VkAq6xOOdY7QM1JjYJRr6HTLqJK9a+xmXRrzPn/Y588dWpNE6MoVF8BImbPkFyd0B4FGRvcf3Cw0JnfF7IWvgSoEefGbRhhxoNx5jqUNlEcBVwLW48wQ4RyQD+dZxz+uESxzIRWeLf9gcgA0BVxwBTcT2G1gF5uPEJtUNsA7huImT/QOniN2g/73Wi934MWQooq+I60u7ap4jIz4L3boLt30LTo3aiMnVVaQmEhbtF4osLYNEr0G4wNGjhdWTGVJtKJQL/w/8N4HQRGQYsUNVjthH4G4CP2QfTX910W2WD9URSBpEDHyBt4AP4fMqGPblM+W47T8xYy+AFyTxxcVciEVc3bIkguBzYA8+f4xqDO13qlpLMy4IzRnsdmTHVqrJTTFwJLAB+DlwJzBeRKwIZWG0UFia0aZjA3ee348/DOjJt+Q7u+jATbdrTJQJT++Vsdd/q3xoJ/zn1yCkgDvKVwqQb3ZoBqe1g3jMw+5+Qdiq0OrtGQzYm0CpbNfRH4HRV3QUgImnAdOCdQAVW2/3yrFaU+pR/TF3FeY07cUn2OOTAHrfmrKmdNs+FVy9yvXoSm7pv+O/f6ur109offuwX/3aDwC563E0Ol7cX1kxzy0faYEMTZCrbuhl2MAn4ZVXh3KB1489O4W/DO/H6nnYIytLZ73odkjkaXylMuxfiG8Gt8+C3K+AXH7lk8NYIKNx/6Nj1n8Osh6HrNdBjlNsWlwzdr4P0Lt7Eb0wAVbZE8LGIfAKM97+/CtfQG/Ku79uSPq1Gkv3co2yY+z5/2tCJtPho6sdFcna7NBuMVlssHgc7lsEVLx3q2ZPYxL1/7RKY8hs47eewfBKs/shVAQ39j337NyGhso3F94rI5bieQAKMVdX3AhpZHdKucX1KOw9m0KppvB0lbM8pYOnWHCYt3kr92EgGtLdlCD2V/yN8/nc3CrjTZYfvO+VsOPfPMP2vsOI9iE2GbtfAWXe7QWDGhIBKT6Sjqu/iBoeZCoS3v4DwZRN4Y3AkNO9NQXEplzz9Nb99awlT7+xPev3YY1/gx02uEbP/7yD6uGP1TFXM+qer4x/0SMXf8PvdBTH1oX6GSwzhxxwiY0zQOWYiEJH9VDDlA65UoKqaGJCo6qLWA0HCYMFY2LGUmNxdjG+1jzcX72b689O49owWhBcfgKJc11DZ59ZDA9BKi+HtG9y0xTtXwNXjIdwmu6vQlgWwYyk07OimbIipf/RjSwpdldCCsdBz1NHr90Wg1y8DE68xdcAxnzaqal9NKyu2gat6WPa2+0FoEBHNbVIAucAM/3GR9aD4gJuqYNDD7iH05X9cEuh8hZvH/uP7YMi/q14/7St1D8nNc+GUAdCo48ndU06mu1bny70fNb3lG5j1f64ht6z4Rq4KJzIOohMhtY2r31cfzH0G9m+DjDNh4J+9iduYOsC+dlanK8dBzhb3cIpLdd/qfT7+MeVb3py3EY2MY1inJvxeXiV1/rNu/vpWP4PZj0KXq+CysZCYDnOehPrNof1gN4CptNglmaOVEkoK4cO7YfUHbuETcH3fb/4aIqJO7F72boBXLoJ9mbDyfbj0OYiOP7FrnajSElgzFb553s3sGZcC5/8NOlwMe9bCzmWuSq043/3kZbmG3sX+sY4ZZ8Klz7p+/9boa8xRVWoa6tqk2tcjqCFLM7N5c/4PTF6yjaKSYj7NeJ3WOz92i5eER8Etc9wcRz4fvH09rPrg8At0HA6XvXDkg10VJt8GS96Abte5KqrSYnj/Zrjg/8GZv6l6sFnrXX/74nxXpfL1464q5uo33dQKpf6V3AJZl754HMx82H2jr9/cze1z+q8rl4wO7HENxCltLAEY43fS6xxni+gAABlISURBVBHUJnU1ERyUk1/MvW9/x8yVW5ma+gRtcxe62Spbn3PooOJ8WDnFzXETl+KqjWb8Ddpe6EodkTGHjv36CfjsQTj7fjinzILob1wJm7+G3yyChMaVDzBrPbwyFEqL4Pop0LgzrJvh2jCKD7hjfCWuKubyF+HUIRVfpygPvvqf66ef0QeadHevK+OLf7tePhl94cw7oN2F7s/CGHPCLBHUMj6f8u9P1/DCrNUMSMslsnFHoiPCSEuI5uazW9OgXgXVOQtfctU/rfq7h2NiE9jzvXtAdxwOV7x8eD1+1np4po/rLnnZc27h9OXvwP4drhRSL9U9nMtOl7x7Dbx6sXvQj5py+Pz5e9bBt+NAwl0SWPMR7FgOV7/hHtRllZbAxJGuWuegsEh33Om/du0XBydx273aJYiUNq6x/fP/B1/+21WVDX/GGs2NqSaWCGqpyUu28uJXG8krKqWwpJTt2QU0SozhyWu70yOjwZEnfDfBTYmgpYe2pXdzSyKWnRv/oBl/dw/VDhe7uZBK8vF3+HL7wyJc76Wz74PsH2DcxW7/qCnHn045PxvGDYddK+Ga8dDmPLddFT78LSx62TV4d7oMtsyHTV+6+PP3QnJr9/DfvdolHXDr+SZluOTWYxQMe8z7BmpjgoglgjpiaWY2t725mO3ZBfx+UHuuOj2D+rHl6uFzd7uG3H1bXT14x0ugXkrFFyw64EoFeXvdqNmeo6BxF3fe/h0wfwx8+xokNIHSQtdWMeoDSG1buYDz9rrksXuN+5bf4kxXPz/3KTjrt3DeXw8/vrgAVk6GJa+7z0rv6ubuKS6Anctd19mMvnD2761u35hqZomgDjnYhvDpyp2IQMf0RHq2aEB8dAQiEBcVwTW9M0iuqPqoIgU57pv/0UbJ/jAfPvqdO+769yGlddUCPpDlFmrf9KX7Ng+uWufS5+xhbkwtYomgjlFVFmzcy7wNe5m/MYvvtmRTVOrDp1DqU7o0q8+E0X2Ii6qm+nNVNwbhZOvjc3fDjxuhSQ+r2zemlvEkEYjIS8AwYJeqdq5g/wBgMrDRv2mSqv7teNcNhURwLJ+t3MlNry3knPYNeW5kTyLCrR7dGHN8x0oEgXyKvAIMOs4xX6pqN//PcZOAgfM7NuKhizsxY/Uu/vrBCupaic4YU/sErPyuql+ISMtAXT+UjezbkszsfJ6bvYFV2/czvFsThpyWTmp8tNehGWPqoIC2EfgTwYfHqBp6F8gEtgH3qOqKo1xnNDAaICMjo+fmzZsDFHHd4fMpL329kYkLt/D9zlzCw4RTUuvRKrUerdLq0TotnjYN3U9ijM2maUyo86yx+DiJIBHwqWquiAwBHlfV4/ZbDPU2goqs3rGPqct2sHr7PjbuOcDmrDyKSn0/7e/dKpk/DulA1+ZJHkZpjPHSsRKBZ107VHVfmddTReQZEUlV1T1exVRXndo4kVMbH5oRvNSnbNmbx7pduazcvo9xczcx/OmvuaRbE+4bfOrx10YwxoQUzxKBiDQGdqqqikhvXMN1llfxBJPwMKFlaj1aptbjvI6NuKFfS56dtZ4Xv9rI7O93M/b6XpzeMtnrMI0xtUTAeg2JyHhgLtBeRDJF5FcicrOI3Ow/5ApguYh8BzwBXK3WBSYgEmIi+f2gU5l2Z38axEVx3fPzee/bTK/DMsbUEjagLMRk5xVxy+uLmbshi1/2a8Ud57YhKe4E1ywwxtQZXo0jMLVQUlwUr/6yNyP6ZPDynI2c9c+Z/OfTNWzPyaewpPT4FzDGBB0rEYSwNTv28/iM75m6bMdP26IiwmjWIJZLuzXlil7NrGHZmCBhcw2ZY1q9Yx/z1meRW1jC/oISvsvMZt6GvYQJnN0ujZF9WzCgXUPCwmwSOWPqqlrZfdTUHuW7nwJszjrA2wszmbhwC798ZSEZyXFc3qMZDROjiYsKJ71+LKe3bIDYDKPG1HlWIjDHVFzq45MVOxg3ZzMLNu09bN+9F7bntnPaeBSZMaYqrERgTlhkeBjDujRhWJcm7C8oJrewhAOFpTz1+Vr+9ckaGiZE8/Nezb0O0xhzEiwRmEpLiIkkwT9v0aNXdGVPbhH3T1pGWkI0A9o39Dg6Y8yJsu6j5oRERYTx7IgetG+UwK1vLObpmevIySv2OixjzAmwRGBOWEJMJK/ccDq9Wibzr0/W0PeRGfx1ygr2HijyOjRjTBVYIjAnpWFiDON+2Ztpd/ZncOd0Xp+3mUGPfcHs73d7HZoxppIsEZhq0SE9kf9c2ZUpt59FUlwko15awF+nrKCg2EYrG1PbWSIw1apjk0Sm3H4WN/RryStzNnHhY1/w1VqbWdyY2swSgal2MZHh/OWiTrx54xmEiTDixfnc/dYStmXnH3acqrJ8a461KRjjMRtQZgKqoLiUp2euY8zs9ZT6lIGnNuLq05uzeW8eExb8wNpdufRs0YB3bu5ro5SNCSCba8h4bsvePCZ88wNvfbOFPbmuBNC1eRLtG8UzcWEmT13bnWFdmngcpTHByxKBqTWKSnx8tW436fVj6ZCeSKlPGfrEl+QWljD97rOJiQz3OkRjgpIn6xGIyEsisktElh9lv4jIEyKyTkSWikiPQMViao+oiDAGntqIDulukrvwMOFPQzuS+WM+L3+9ydvgjAlRgWwsfgUYdIz9g4G2/p/RwLMBjMXUYme1TeXcUxvy9Mx17N5f6HU4xoScgCUCVf0C2HuMQ4YD49SZBySJSHqg4jG12x+GdqCguJT73l1KbmGJ1+EYE1K87D7aFNhS5n2mf9sRRGS0iCwUkYW7d9uI1WDUOi2ePw3twKw1u7joya9YsS3H65CMCRleJoKK+gpW2HKtqmNVtZeq9kpLSwtwWMYrv+jXivE39iGvqIRLn5nDI9NWM3P1LrJyrbrImEDychrqTKDsRPbNgG0exWJqiTNOSWHqHf25f9IynvtiPWNmrwega7P6/PXiTnTPaOBxhMYEHy8TwRTgdhGZAJwB5Kjqdg/jMbVESnw0z1/fiwOFJSzfmsO3W7J5+euNXPbsHK7tncHvLzyV+nGRXodpTNAI2DgCERkPDABSgZ3AX4BIAFUdI24Y6VO4nkV5wA2qetwBAjaOIDTlFpbwv8++5+WvN5JcL4o/De3I8G5NbDSyMZVkA8pM0FixLYc/vrecJVuyOatNKn+/pDOtUut5HZYxtZ4nA8qMCYROTerz7i1n8vfhnfhuSzYX/u8LHp66in0FtjqaMSfKEoGpc8LDhJF9WzLjd2czvFsTxn65gXP+NYsJC36grpVwjakNLBGYOqthYgz/+nlXPrj9LFo3jOf+Scv465QV+HyWDIypCksEps7r3LQ+E27sw439W/Hq3M3c+dYSikp8XodlTJ3hZfdRY6pNWJjwx6EdSY2P5uFpq9l7oJDfnteOHhkNCAuznkXGHIslAhNUbjq7NQ3qRfHnycu5YsxcmibFckn3Jtx2ThviouyfuzEVsf8ZJuhc2as5Q05L57OVO5i8ZBvPzlrP1+uyeOkXp5NcL8rr8IypdayNwASl+OgILu3ejFdu6M2zI3qyavs+rhgzh8wf87wOzZhaxxKBCXoXdmrMa786gz37C7n82TlMXrKVklJrTDbmIEsEJiT0bpXM2zefSWJMJHdOWMI5/5nFa/M2U2wJwRhLBCZ0tG+cwCd3/YyxI3uSUi+aB99fzjVj57FrX4HXoRnjKUsEJqSEhQkXdGrMe7eeyRPXdGfl9n0MffIrFmw81mJ6xgQ36zVkQpKIcHHXJpzaOIGbXlvEtc/Po0N6IinxUaTFR/OLfi3p1KS+12EaUyOsRGBCWrtGCUy+vR+jzmxJSnwUWblFfLxiByNemM+G3bleh2dMjbBpqI0pZ3PWAS57Zg5x0eFMuqUfaQnRXodkzEmzaaiNqYIWKfV48Rens3t/Ib969RsWbd7LpMWZPDb9e5ZsyfY6PGOqXUBLBCIyCHgcCAdeUNVHyu0fAEwGNvo3TVLVvx3rmlYiMDVl+sqdjH5tIWUnM02IjuCjO/qTkRLnXWDGnIBjlQgC1lgsIuHA08D5uIXqvxGRKaq6styhX6rqsEDFYcyJOq9jI96/rR+79hXSMrUe4WHC8Ke+4jfjF/P2zWcSFWEFahMcAvkvuTewTlU3qGoRMAEYHsDPM6badWmWxHkdG9GmYTytUuvx6BVd+C4zh0c/Xu11aMZUm0AmgqbAljLvM/3byusrIt+JyDQR6VTRhURktIgsFJGFu3fvDkSsxlTKoM7pjOrbghe+2sgnK3Z4HY4x1SKQiaCiSeDLN0gsBlqoalfgSeD9ii6kqmNVtZeq9kpLS6vmMI2pmgeGdKBz00Rufn0RD32wgryiEq9DMuakBHJAWSbQvMz7ZsC2sgeo6r4yr6eKyDMikqqqewIYlzEnJSYynAmj+/Lox6t5+etNTF+1k5vPbk1KvSjioyM5Ja0eTZJivQ7TmEoLZCL4BmgrIq2ArcDVwLVlDxCRxsBOVVUR6Y0roWQFMCZjqkV8dAR/G96ZYV2acN+7S/nje8t/2hcVHsYd57bhprNbExluDcqm9gtYIlDVEhG5HfgE1330JVVdISI3+/ePAa4AbhGREiAfuFrr2gg3E9J6t0rms9/+jO05BeQWlrAvv5jX5m3m359+z9RlO3j0ii50bmpTVZjazUYWGxMAHy/fwZ/eX86e3ELO69CIWwacQs8WyV6HZUKYJ+MIjAllgzo3pu8pKbz09UZenbuJy5/dyamNE2iaFEv9uEiaN4jj1/1bkRAT6XWoxliJwJhAyysq4a1vtjB91U6y84rJzitme04+GclxPHlND05rZlVHJvCOVSKwRGCMBxZs3MudE75lT24h917YnpF9WhIbFe51WCaIWSIwphbKzivi3neW8tnKncRGhjPw1IYM65LOhZ0aExZW0TAcY06ctREYUwslxUUxdmRP5m7I4qOl2/lkxQ4+Wrad8zs24n9XdSM+2v57mpphJQJjaolSn/LqnE38Y+oqWqfV4/nre9EipZ7XYZkgYSUCY+qA8DDhl2e1on3jBG59YzEXP/U1Q7uk0715El2aJeFTJSu3iJz8Ys5snUKDelFeh2yChJUIjKmFNmcd4KEPVvLNxr3sLzxyLqOmSbG8MKoXHdITPYjO1EXWWGxMHeXzKRv25LJ86z6iI8JIiY+moLiUe9/5jv0FJTx2VTcu6NTY6zBNHWCJwJggs3NfAaPHLeS7zByaJ8eSV1hKXlEpvVsl87fhnaxtwRzBEoExQaiguJTHpq9lR04+9aIjCA8TJi3eSnGpjzvObcvpLZP5cu1uvly7h8TYSO65oB1dmiV5HbbxiCUCY0LEjpwC/vbhCqYuc4vmhIcJXZvVZ3NWHlkHihjerQl3ntuWU9LiPY7U1DRLBMaEmHkbssjOK6Zv6xTqx0ayv6CYMbPX88KXGyks8dE0KZY+p6RwRqtkujZPok3DeMJtEFtQs0RgjAFge04+n67YybwNWczbkMWPecUAxEWF06lJIu0bJ9C+UQKtUuOpFx1OvegIkmIjaZgY43Hk5mRZIjDGHMH1SDrA0sxsvtuSzfJt+/h+5372FxzZXTUjOY5+bVLo1yaVM1unklxmDMOBwhJW79hPh/QE4qJsaFJtZYnAGFMpqsrOfYVsyjpAXlEJeUWl7NxXyNz1WczfkPXTmIYO6Yl0a57Emh37WJqZQ4lPSYyJ4OreGYzs04LmyXEe34kpz7NEICKDgMdxK5S9oKqPlNsv/v1DgDzgF6q6+FjXtERgjDdKSn0s3ZrDnHV7+HpdFsu25tCuUTx9TkmhQ3oiH6/YwcfLd+BTJTU+mgZxkTSIi6JhYgxN6sfQJCmWhgnRpCZEkxofTXJcFPExEdY2UUM8SQQiEg58D5yPW8j+G+AaVV1Z5pghwG9wieAM4HFVPeNY17VEYEzttT0nn3cXZbI1O5+9B4r48UAxO/cXsD27gKJSX4XnJMREEBsZTkSYEB4uxEaGk1wviuR6UcRGRlDi81FSqpT4fPjUlVpAiIkMIzYynLiocOKiI6gXFU5sVAQxkWFER4QTHRHmfiLd64gwISxM3OeECZHhbltkeBhR/v3hYYIgSBiEiRAm7rfb7l6LgPsOW7d4NddQb2Cdqm7wBzEBGA6sLHPMcGCcf53ieSKSJCLpqro9gHEZYwIkvX4stw9se8R2n0/JOlDErv0F7MktYs/+QrLzi8nJL2ZffjEFxaWU+pRSn3KgqIQf84r5fmcu+UWlRIS7h3dEWBhhYe7h7FMoLC6loLiUvOJS8gpLj5poAiFMXNdcEZcgREBwCePgPpc0XOIof27YT+cd2hkW5q5xsIB08Ct62QR0Te8Mft3/lGq/n0AmgqbAljLvM3Hf+o93TFPgsEQgIqOB0QAZGRnVHqgxJrDCwoS0hGjSEqID9hlFJT7yi0opLCmloNhHQUkpRSU+CktKKSz2UeJTSlUpLVVKfPpTSaO41Eex/3epT1FcqUMVd7xPUVV/acRt8/mv5VP96YntU6XUd/C3ouhhJRjHXdfnvx64ayruOge3H8wPgru8z78vNT4wf36BTAQVlZ3K10NV5hhUdSwwFlzV0MmHZowJNlERrooHbB3oqgoL4LUzgeZl3jcDtp3AMcYYYwIokIngG6CtiLQSkSjgamBKuWOmANeL0wfIsfYBY4ypWQGrGlLVEhG5HfgE1330JVVdISI3+/ePAabiegytw3UfvSFQ8RhjjKlYQIcBqupU3MO+7LYxZV4rcFsgYzDGGHNsgawaMsYYUwdYIjDGmBBnicAYY0KcJQJjjAlxdW72URHZDWw+wdNTgT3VGE5dEYr3HYr3DKF536F4z1D1+26hqmkV7ahzieBkiMjCo026FMxC8b5D8Z4hNO87FO8Zqve+rWrIGGNCnCUCY4wJcaGWCMZ6HYBHQvG+Q/GeITTvOxTvGarxvkOqjcAYY8yRQq1EYIwxphxLBMYYE+JCJhGIyCARWSMi60Tkfq/jCQQRaS4iM0VklYisEJE7/duTReQzEVnr/93A61irm4iEi8i3IvKh/30o3HOSiLwjIqv9f+d9Q+S+f+v/971cRMaLSEyw3beIvCQiu0RkeZltR71HEXnA/2xbIyIXVvXzQiIRiEg48DQwGOgIXCMiHb2NKiBKgN+pagegD3Cb/z7vB2aoaltghv99sLkTWFXmfSjc8+PAx6p6KtAVd/9Bfd8i0hS4A+ilqp1xU9xfTfDd9yvAoHLbKrxH///xq4FO/nOe8T/zKi0kEgHQG1inqhtUtQiYAAz3OKZqp6rbVXWx//V+3IOhKe5eX/Uf9ipwiTcRBoaINAOGAi+U2Rzs95wI/Ax4EUBVi1Q1myC/b78IIFZEIoA43KqGQXXfqvoFsLfc5qPd43BggqoWqupG3PouvavyeaGSCJoCW8q8z/RvC1oi0hLoDswHGh1c+c3/u6F3kQXEY8DvAV+ZbcF+z6cAu4GX/VViL4hIPYL8vlV1K/Bv4AdgO25Vw08J8vv2O9o9nvTzLVQSgVSwLWj7zYpIPPAucJeq7vM6nkASkWHALlVd5HUsNSwC6AE8q6rdgQPU/eqQ4/LXiw8HWgFNgHoiMsLbqDx30s+3UEkEmUDzMu+b4YqTQUdEInFJ4A1VneTfvFNE0v3704FdXsUXAP2Ai0VkE67Kb6CIvE5w3zO4f9OZqjrf//4dXGII9vs+D9ioqrtVtRiYBJxJ8N83HP0eT/r5FiqJ4BugrYi0EpEoXMPKFI9jqnYiIrg641Wq+t8yu6YAo/yvRwGTazq2QFHVB1S1maq2xP29fq6qIwjiewZQ1R3AFhFp7990LrCSIL9vXJVQHxGJ8/97PxfXFhbs9w1Hv8cpwNUiEi0irYC2wIIqXVlVQ+IHGAJ8D6wH/uh1PAG6x7NwRcKlwBL/zxAgBdfLYK3/d7LXsQbo/gcAH/pfB/09A92Ahf6/7/eBBiFy3w8Bq4HlwGtAdLDdNzAe1wZSjPvG/6tj3SPwR/+zbQ0wuKqfZ1NMGGNMiAuVqiFjjDFHYYnAGGNCnCUCY4wJcZYIjDEmxFkiMMaYEGeJwJgaJCIDDs6QakxtYYnAGGNCnCUCYyogIiNEZIGILBGR5/zrHeSKyH9EZLGIzBCRNP+x3URknogsFZH3Ds4TLyJtRGS6iHznP6e1//LxZdYReMM/QtYYz1giMKYcEekAXAX0U9VuQClwHVAPWKyqPYDZwF/8p4wD7lPVLsCyMtvfAJ5W1a64+XC2+7d3B+7CrY1xCm6+JGM8E+F1AMbUQucCPYFv/F/WY3ETfPmAt/zHvA5MEpH6QJKqzvZvfxV4W0QSgKaq+h6AqhYA+K+3QFUz/e+XAC2BrwJ/W8ZUzBKBMUcS4FVVfeCwjSIPljvuWPOzHKu6p7DM61Ls/6HxmFUNGXOkGcAVItIQflortgXu/8sV/mOuBb5S1RzgRxHp798+Epitbh2ITBG5xH+NaBGJq9G7MKaS7JuIMeWo6koR+RPwqYiE4WaAvA23+EsnEVkE5ODaEcBNCTzG/6DfANzg3z4SeE5E/ua/xs9r8DaMqTSbfdSYShKRXFWN9zoOY6qbVQ0ZY0yIsxKBMcaEOCsRGGNMiLNEYIwxIc4SgTHGhDhLBMYYE+IsERhjTIj7/2iVnnm7wWKhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at D:\\Projects\\ESA\\audio-sentiment-analysis\\prototypes\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 43.96%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16879869, 0.02109269, 0.183692  , ..., 0.10259657, 0.22244832,\n",
       "        0.09629356],\n",
       "       [0.23596318, 0.10923008, 0.0417158 , ..., 0.03229681, 0.06905668,\n",
       "        0.26862612],\n",
       "       [0.10233006, 0.61442405, 0.06422991, ..., 0.01306609, 0.02684782,\n",
       "        0.05012532],\n",
       "       ...,\n",
       "       [0.22926757, 0.07640006, 0.06560344, ..., 0.02389086, 0.18495321,\n",
       "        0.16268146],\n",
       "       [0.1790455 , 0.37358436, 0.04318428, ..., 0.03698333, 0.04661356,\n",
       "        0.16054548],\n",
       "       [0.24608195, 0.08227899, 0.10976911, ..., 0.05919385, 0.18360728,\n",
       "        0.14945805]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 1, 6, 0, 7, 1, 2, 1, 0, 2, 3, 0, 7, 0, 7, 3, 3, 2, 2, 1, 3,\n",
       "       7, 7, 0, 2, 7, 2, 3, 6, 7, 2, 6, 2, 6, 7, 0, 0, 6, 1, 7, 0, 0, 3,\n",
       "       6, 6, 3, 2, 1, 1, 6, 2, 7, 3, 0, 7, 3, 0, 0, 2, 7, 2, 0, 3, 6, 2,\n",
       "       3, 3, 0, 0, 7, 0, 7, 6, 2, 1, 0, 0, 3, 0, 6, 1, 7, 2, 2, 0, 0, 2,\n",
       "       7, 7, 6, 0, 7, 0, 7, 7, 1, 2, 2, 0, 6, 0, 2, 3, 2, 3, 7, 0, 0, 2,\n",
       "       7, 0, 2, 2, 0, 6, 6, 2, 0, 0, 6, 0, 3, 0, 0, 1, 0, 1, 2, 1, 0, 2,\n",
       "       2, 2, 7, 2, 6, 0, 0, 3, 2, 0, 3, 0, 6, 0, 7, 0, 1, 2, 0, 3, 6, 0,\n",
       "       3, 2, 2, 0, 2, 7, 0, 2, 2, 7, 2, 0, 0, 7, 0, 2, 2, 0, 3, 0, 1, 7,\n",
       "       7, 7, 3, 7, 0, 2, 3, 2, 0, 7, 1, 0, 2, 2, 0, 0, 0, 2, 3, 6, 6, 7,\n",
       "       2, 0, 6, 2, 0, 3, 2, 7, 0, 0, 2, 2, 0, 3, 0, 3, 7, 1, 0, 6, 0, 0,\n",
       "       0, 2, 0, 0, 0, 7, 2, 0, 0, 0, 6, 2, 0, 2, 0, 0, 0, 3, 7, 0, 7, 0,\n",
       "       6, 6, 0, 7, 0, 0, 2, 3, 1, 0, 6, 0, 2, 2, 2, 0, 0, 0, 6, 7, 6, 3,\n",
       "       0, 0, 2, 7, 3, 3, 1, 0, 0, 7, 0, 2, 0, 0, 6, 3, 7, 7, 3, 2, 7, 0,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictedvalues\n",
       "0               sad\n",
       "1         surprised\n",
       "2             angry\n",
       "3               sad\n",
       "4             Happy\n",
       "..              ...\n",
       "283            calm\n",
       "284       surprised\n",
       "285           Happy\n",
       "286           angry\n",
       "287           Happy\n",
       "\n",
       "[288 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actualvalues\n",
       "0          Happy\n",
       "1          angry\n",
       "2          angry\n",
       "3            sad\n",
       "4        fearful\n",
       "..           ...\n",
       "283        Happy\n",
       "284      fearful\n",
       "285      fearful\n",
       "286        angry\n",
       "287        Happy\n",
       "\n",
       "[288 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actualvalues predictedvalues\n",
       "0        Happy             sad\n",
       "1        angry       surprised\n",
       "2        angry           angry\n",
       "3          sad             sad"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Happy</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calm</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fearful</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprised</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predictedvalues\n",
       "actualvalues                 \n",
       "Happy                      39\n",
       "angry                      42\n",
       "calm                       33\n",
       "disgust                    41\n",
       "fearful                    48\n",
       "neutral                    18\n",
       "sad                        35\n",
       "surprised                  32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Happy</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calm</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprised</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actualvalues\n",
       "predictedvalues              \n",
       "Happy                      96\n",
       "angry                      20\n",
       "calm                       61\n",
       "disgust                    34\n",
       "sad                        31\n",
       "surprised                  46"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## you could find this track on below link:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tuenl.sharepoint.com/sites/gad_cbo/JPC/MC/ESA%20PDEng%20ST%20Project/Forms/AllItems.aspx?viewid=235c9f56%2Db4dc%2D418e%2D8800%2Dd0cde58fff30&id=%2Fsites%2Fgad%5Fcbo%2FJPC%2FMC%2FESA%20PDEng%20ST%20Project%2FModelsAndData%2FAudio%2FDevelopment%2Fdata%2Ftone%5Fcnn%5Fhappy%5Fangry%5Fdataset%5Fsample%5Fprediction%5Ftracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking a directory tree and getting the names and directories of the prediction files\n",
    "mydiclist={}\n",
    "curr_path = os.getcwd()\n",
    "crr_path = Path(curr_path)\n",
    "parent_path = crr_path.parent\n",
    "base_path= str(parent_path)+'\\\\data\\\\tone_cnn_prediction_dataset\\\\'\n",
    "for dirpath, dirnames, files in os.walk(base_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.wav'):\n",
    "            mydiclist[file_name]= dirpath\n",
    "\n",
    "    \n",
    "#X, sample_rate = librosa.load(str(base_path) +'\\\\Recording_hateYou.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "#sample_rate = np.array(sample_rate)\n",
    "#mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "#featurelive = mfccs\n",
    "#livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step\n",
      "['multiple_silence_trimmed.wav  :  fearful']\n",
      "1/1 [==============================] - 0s 997us/step\n",
      "['Recording_hateYou.wav  :  surprised']\n"
     ]
    }
   ],
   "source": [
    "for key in mydiclist:\n",
    "    X, sample_rate = librosa.load(mydiclist[key]+'\\\\'+key, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "    featurelive = mfccs\n",
    "    livedf2 = featurelive\n",
    "    livedf2= pd.DataFrame(data=livedf2)\n",
    "    livedf2 = livedf2.stack().to_frame().T\n",
    "    twodim= np.expand_dims(livedf2, axis=2)\n",
    "    livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)\n",
    "    livepreds1=livepreds.argmax(axis=1)\n",
    "    liveabc = livepreds1.astype(int).flatten()\n",
    "    livepredictions = (lb.inverse_transform((liveabc)))\n",
    "    print(key+\"  :  \"+ livepredictions)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
