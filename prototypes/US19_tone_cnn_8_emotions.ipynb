{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from keras.layers.normalization import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking a directory tree and getting the names and directories of the train and test files \n",
    "mydiclist={}\n",
    "curr_path = os.getcwd()\n",
    "crr_path = Path(curr_path)\n",
    "parent_path = crr_path.parent\n",
    "path= str(parent_path)+'\\\\data\\\\tone_cnn_8_emotions_dataset\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data loaded. Loading time: 181.33810925483704 seconds ---\n",
      "(5252, 40) (5252,)\n"
     ]
    }
   ],
   "source": [
    "   \"\"\"\n",
    "        This function creates the dataset and saves both data and labels in\n",
    "        two files, X.joblib and y.joblib in the joblib_features folder.\n",
    "        With this method, you can persist your features and train quickly\n",
    "        new machine learning models instead of reloading the features\n",
    "        every time with this pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "lst = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "            try:\n",
    "                # Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "                X, sample_rate = librosa.load(os.path.join(subdir, file),\n",
    "                                                  res_type='kaiser_fast')\n",
    "                mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate,\n",
    "                                                         n_mfcc=40).T, axis=0)\n",
    "                # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "                # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "                file = int(file[7:8]) - 1\n",
    "                arr = mfccs, file\n",
    "                lst.append(arr)\n",
    "            # If the file is not valid, skip it\n",
    "            except ValueError as err:\n",
    "                print(err)\n",
    "                continue\n",
    "\n",
    "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
    "X, y = zip(*lst)\n",
    "\n",
    "# Array conversion\n",
    "X, y = np.asarray(X), np.asarray(y)\n",
    "\n",
    "# Array shape check\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5252, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 5, padding='same',\n",
    "                         input_shape=(40, 1)))\n",
    "    model.add(Conv1D(128, 5, padding='same',\n",
    "                         input_shape=(40, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "        #model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8))\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 5, padding='same',\n",
    "                         input_shape=(40, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, 5, padding='same',\n",
    "                         input_shape=(40, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "       #model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8))\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def train_neural_network(X, y) -> None:\n",
    "        \"\"\"\n",
    "        This function trains the neural network.\n",
    "        \"\"\"\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "        x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "        x_testcnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "        print(x_traincnn.shape, x_testcnn.shape)\n",
    "\n",
    "        model = model2()\n",
    "        print(model.summary)\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy',#categorical_crossentropy sparse_categorical_crossentropy\n",
    "                      optimizer= opt, #'rmsprop', #,#rmsprop #opt\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        cnn_history = model.fit(x_traincnn, y_train,\n",
    "                               batch_size=10, epochs=200,\n",
    "                               validation_data=(x_testcnn, y_test))\n",
    "\n",
    "        # Loss plotting\n",
    "        plt.plot(cnn_history.history['loss'])\n",
    "        plt.plot(cnn_history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.savefig('loss.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Accuracy plotting\n",
    "        plt.plot(cnn_history.history['accuracy'])\n",
    "        plt.plot(cnn_history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.savefig('accuracy.png')\n",
    "\n",
    "        predictions = model.predict_classes(x_testcnn)\n",
    "        new_y_test = y_test.astype(int)\n",
    "        matrix = confusion_matrix(new_y_test, predictions)\n",
    "\n",
    "        print(classification_report(new_y_test, predictions))\n",
    "        print(matrix)\n",
    "\n",
    "        model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "\n",
    "        # Save model and weights\n",
    "        save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        model_path = os.path.join(save_dir, model_name)\n",
    "        model.save(model_path)\n",
    "        print('Saved trained model at %s ' % model_path)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3518, 40, 1) (1734, 40, 1)\n",
      "<bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000002A8591F6708>>\n",
      "Epoch 1/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.4731 - accuracy: 0.5043 - val_loss: 0.9945 - val_accuracy: 0.6275\n",
      "Epoch 2/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.0143 - accuracy: 0.6475 - val_loss: 0.8084 - val_accuracy: 0.7186\n",
      "Epoch 3/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8678 - accuracy: 0.6995 - val_loss: 0.8174 - val_accuracy: 0.6990\n",
      "Epoch 4/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7758 - accuracy: 0.7271 - val_loss: 0.6947 - val_accuracy: 0.7514\n",
      "Epoch 5/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7347 - accuracy: 0.7365 - val_loss: 0.6915 - val_accuracy: 0.7393\n",
      "Epoch 6/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6970 - accuracy: 0.7513 - val_loss: 0.6396 - val_accuracy: 0.7762\n",
      "Epoch 7/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6491 - accuracy: 0.7635 - val_loss: 0.6804 - val_accuracy: 0.7555\n",
      "Epoch 8/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6205 - accuracy: 0.7740 - val_loss: 0.5867 - val_accuracy: 0.7820\n",
      "Epoch 9/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.5872 - accuracy: 0.7769 - val_loss: 0.5687 - val_accuracy: 0.7889\n",
      "Epoch 10/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5813 - accuracy: 0.7953 - val_loss: 0.5629 - val_accuracy: 0.7947\n",
      "Epoch 11/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5454 - accuracy: 0.8053 - val_loss: 0.5484 - val_accuracy: 0.8097\n",
      "Epoch 12/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5365 - accuracy: 0.8073 - val_loss: 0.5474 - val_accuracy: 0.8103\n",
      "Epoch 13/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5117 - accuracy: 0.8096 - val_loss: 0.5280 - val_accuracy: 0.8039\n",
      "Epoch 14/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5089 - accuracy: 0.8212 - val_loss: 0.5023 - val_accuracy: 0.8224\n",
      "Epoch 15/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4621 - accuracy: 0.8363 - val_loss: 0.5043 - val_accuracy: 0.8201\n",
      "Epoch 16/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.4593 - accuracy: 0.8357 - val_loss: 0.4789 - val_accuracy: 0.8328\n",
      "Epoch 17/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4514 - accuracy: 0.8351 - val_loss: 0.5290 - val_accuracy: 0.8062\n",
      "Epoch 18/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4388 - accuracy: 0.8391 - val_loss: 0.4622 - val_accuracy: 0.8443\n",
      "Epoch 19/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4074 - accuracy: 0.8522 - val_loss: 0.4638 - val_accuracy: 0.8195\n",
      "Epoch 20/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.4026 - accuracy: 0.8502 - val_loss: 0.4936 - val_accuracy: 0.8235\n",
      "Epoch 21/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4107 - accuracy: 0.8508 - val_loss: 0.4819 - val_accuracy: 0.8391\n",
      "Epoch 22/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3853 - accuracy: 0.8619 - val_loss: 0.4492 - val_accuracy: 0.8397\n",
      "Epoch 23/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3694 - accuracy: 0.8627 - val_loss: 0.4418 - val_accuracy: 0.8397\n",
      "Epoch 24/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3681 - accuracy: 0.8661 - val_loss: 0.4533 - val_accuracy: 0.8403\n",
      "Epoch 25/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3542 - accuracy: 0.8690 - val_loss: 0.4568 - val_accuracy: 0.8339\n",
      "Epoch 26/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3542 - accuracy: 0.8698 - val_loss: 0.4806 - val_accuracy: 0.8374\n",
      "Epoch 27/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3364 - accuracy: 0.8735 - val_loss: 0.4634 - val_accuracy: 0.8368\n",
      "Epoch 28/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3287 - accuracy: 0.8798 - val_loss: 0.4822 - val_accuracy: 0.8287\n",
      "Epoch 29/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3266 - accuracy: 0.8826 - val_loss: 0.4461 - val_accuracy: 0.8426\n",
      "Epoch 30/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3261 - accuracy: 0.8789 - val_loss: 0.4251 - val_accuracy: 0.8535\n",
      "Epoch 31/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3086 - accuracy: 0.8951 - val_loss: 0.4168 - val_accuracy: 0.8512\n",
      "Epoch 32/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3098 - accuracy: 0.8829 - val_loss: 0.4210 - val_accuracy: 0.8518\n",
      "Epoch 33/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2904 - accuracy: 0.8943 - val_loss: 0.4288 - val_accuracy: 0.8547\n",
      "Epoch 34/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.3030 - accuracy: 0.8866 - val_loss: 0.4278 - val_accuracy: 0.8408\n",
      "Epoch 35/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2665 - accuracy: 0.9034 - val_loss: 0.4397 - val_accuracy: 0.8443\n",
      "Epoch 36/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2659 - accuracy: 0.9039 - val_loss: 0.4431 - val_accuracy: 0.8529\n",
      "Epoch 37/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2797 - accuracy: 0.8991 - val_loss: 0.4644 - val_accuracy: 0.8454\n",
      "Epoch 38/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2671 - accuracy: 0.9070 - val_loss: 0.4316 - val_accuracy: 0.8558\n",
      "Epoch 39/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2576 - accuracy: 0.9082 - val_loss: 0.4408 - val_accuracy: 0.8506\n",
      "Epoch 40/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2513 - accuracy: 0.9096 - val_loss: 0.4658 - val_accuracy: 0.8478\n",
      "Epoch 41/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2602 - accuracy: 0.9008 - val_loss: 0.4333 - val_accuracy: 0.8518\n",
      "Epoch 42/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2455 - accuracy: 0.9122 - val_loss: 0.4618 - val_accuracy: 0.8426\n",
      "Epoch 43/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2290 - accuracy: 0.9190 - val_loss: 0.4514 - val_accuracy: 0.8495\n",
      "Epoch 44/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2369 - accuracy: 0.9164 - val_loss: 0.4170 - val_accuracy: 0.8570\n",
      "Epoch 45/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2398 - accuracy: 0.9110 - val_loss: 0.4293 - val_accuracy: 0.8587\n",
      "Epoch 46/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2225 - accuracy: 0.9196 - val_loss: 0.4393 - val_accuracy: 0.8564\n",
      "Epoch 47/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2140 - accuracy: 0.9187 - val_loss: 0.4420 - val_accuracy: 0.8466\n",
      "Epoch 48/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2326 - accuracy: 0.9179 - val_loss: 0.4665 - val_accuracy: 0.8478\n",
      "Epoch 49/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2135 - accuracy: 0.9187 - val_loss: 0.4453 - val_accuracy: 0.8587\n",
      "Epoch 50/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2190 - accuracy: 0.9210 - val_loss: 0.4371 - val_accuracy: 0.8570\n",
      "Epoch 51/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2136 - accuracy: 0.9213 - val_loss: 0.4465 - val_accuracy: 0.8564\n",
      "Epoch 52/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1966 - accuracy: 0.9267 - val_loss: 0.4147 - val_accuracy: 0.8702\n",
      "Epoch 53/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1917 - accuracy: 0.9332 - val_loss: 0.4239 - val_accuracy: 0.8599\n",
      "Epoch 54/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2117 - accuracy: 0.9241 - val_loss: 0.4205 - val_accuracy: 0.8587\n",
      "Epoch 55/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1990 - accuracy: 0.9309 - val_loss: 0.4156 - val_accuracy: 0.8604\n",
      "Epoch 56/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2012 - accuracy: 0.9281 - val_loss: 0.4241 - val_accuracy: 0.8627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1880 - accuracy: 0.9346 - val_loss: 0.4275 - val_accuracy: 0.8604\n",
      "Epoch 58/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1879 - accuracy: 0.9355 - val_loss: 0.4410 - val_accuracy: 0.8622\n",
      "Epoch 59/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1920 - accuracy: 0.9309 - val_loss: 0.4555 - val_accuracy: 0.8535\n",
      "Epoch 60/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1748 - accuracy: 0.9389 - val_loss: 0.4358 - val_accuracy: 0.8518\n",
      "Epoch 61/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1758 - accuracy: 0.9360 - val_loss: 0.4414 - val_accuracy: 0.8587\n",
      "Epoch 62/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1681 - accuracy: 0.9426 - val_loss: 0.4234 - val_accuracy: 0.8720\n",
      "Epoch 63/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1663 - accuracy: 0.9372 - val_loss: 0.4297 - val_accuracy: 0.8604\n",
      "Epoch 64/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1732 - accuracy: 0.9403 - val_loss: 0.4105 - val_accuracy: 0.8651\n",
      "Epoch 65/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1772 - accuracy: 0.9352 - val_loss: 0.4803 - val_accuracy: 0.8512\n",
      "Epoch 66/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1518 - accuracy: 0.9451 - val_loss: 0.4497 - val_accuracy: 0.8651\n",
      "Epoch 67/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1582 - accuracy: 0.9423 - val_loss: 0.4101 - val_accuracy: 0.8708\n",
      "Epoch 68/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1577 - accuracy: 0.9437 - val_loss: 0.4091 - val_accuracy: 0.8783\n",
      "Epoch 69/200\n",
      "352/352 [==============================] - 2s 7ms/step - loss: 0.1574 - accuracy: 0.9426 - val_loss: 0.4560 - val_accuracy: 0.8616\n",
      "Epoch 70/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1602 - accuracy: 0.9412 - val_loss: 0.4636 - val_accuracy: 0.8587\n",
      "Epoch 71/200\n",
      "352/352 [==============================] - 2s 7ms/step - loss: 0.1603 - accuracy: 0.9488 - val_loss: 0.4493 - val_accuracy: 0.8581\n",
      "Epoch 72/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1608 - accuracy: 0.9434 - val_loss: 0.4196 - val_accuracy: 0.8697\n",
      "Epoch 73/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1352 - accuracy: 0.9520 - val_loss: 0.4163 - val_accuracy: 0.8697\n",
      "Epoch 74/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1397 - accuracy: 0.9488 - val_loss: 0.4115 - val_accuracy: 0.8754\n",
      "Epoch 75/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1539 - accuracy: 0.9483 - val_loss: 0.4463 - val_accuracy: 0.8633\n",
      "Epoch 76/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1417 - accuracy: 0.9517 - val_loss: 0.4417 - val_accuracy: 0.8645\n",
      "Epoch 77/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.4375 - val_accuracy: 0.8697\n",
      "Epoch 78/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1427 - accuracy: 0.9463 - val_loss: 0.4782 - val_accuracy: 0.8616\n",
      "Epoch 79/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1439 - accuracy: 0.9468 - val_loss: 0.4658 - val_accuracy: 0.8622\n",
      "Epoch 80/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1407 - accuracy: 0.9542 - val_loss: 0.4537 - val_accuracy: 0.8633\n",
      "Epoch 81/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1385 - accuracy: 0.9474 - val_loss: 0.4535 - val_accuracy: 0.8604\n",
      "Epoch 82/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1446 - accuracy: 0.9454 - val_loss: 0.4369 - val_accuracy: 0.8651\n",
      "Epoch 83/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1399 - accuracy: 0.9520 - val_loss: 0.4452 - val_accuracy: 0.8702\n",
      "Epoch 84/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1337 - accuracy: 0.9517 - val_loss: 0.4375 - val_accuracy: 0.8656\n",
      "Epoch 85/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1400 - accuracy: 0.9483 - val_loss: 0.5060 - val_accuracy: 0.8512\n",
      "Epoch 86/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1280 - accuracy: 0.9557 - val_loss: 0.4770 - val_accuracy: 0.8645\n",
      "Epoch 87/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1104 - accuracy: 0.9662 - val_loss: 0.4527 - val_accuracy: 0.8616\n",
      "Epoch 88/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1277 - accuracy: 0.9585 - val_loss: 0.4676 - val_accuracy: 0.8702\n",
      "Epoch 89/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1329 - accuracy: 0.9565 - val_loss: 0.4814 - val_accuracy: 0.8622\n",
      "Epoch 90/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1205 - accuracy: 0.9545 - val_loss: 0.4789 - val_accuracy: 0.8627\n",
      "Epoch 91/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1207 - accuracy: 0.9579 - val_loss: 0.4597 - val_accuracy: 0.8633\n",
      "Epoch 92/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1206 - accuracy: 0.9540 - val_loss: 0.4995 - val_accuracy: 0.8685\n",
      "Epoch 93/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1312 - accuracy: 0.9477 - val_loss: 0.4428 - val_accuracy: 0.8720\n",
      "Epoch 94/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1312 - accuracy: 0.9545 - val_loss: 0.4426 - val_accuracy: 0.8800\n",
      "Epoch 95/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1228 - accuracy: 0.9588 - val_loss: 0.4578 - val_accuracy: 0.8662\n",
      "Epoch 96/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1290 - accuracy: 0.9551 - val_loss: 0.5043 - val_accuracy: 0.8610\n",
      "Epoch 97/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1226 - accuracy: 0.9628 - val_loss: 0.4772 - val_accuracy: 0.8679\n",
      "Epoch 98/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1213 - accuracy: 0.9599 - val_loss: 0.4627 - val_accuracy: 0.8662\n",
      "Epoch 99/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.4537 - val_accuracy: 0.8720\n",
      "Epoch 100/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1227 - accuracy: 0.9582 - val_loss: 0.4973 - val_accuracy: 0.8679\n",
      "Epoch 101/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1152 - accuracy: 0.9616 - val_loss: 0.4980 - val_accuracy: 0.8604\n",
      "Epoch 102/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1134 - accuracy: 0.9576 - val_loss: 0.4595 - val_accuracy: 0.8708\n",
      "Epoch 103/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1112 - accuracy: 0.9630 - val_loss: 0.4289 - val_accuracy: 0.8783\n",
      "Epoch 104/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1064 - accuracy: 0.9602 - val_loss: 0.4266 - val_accuracy: 0.8812\n",
      "Epoch 105/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1232 - accuracy: 0.9588 - val_loss: 0.4600 - val_accuracy: 0.8685\n",
      "Epoch 106/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1055 - accuracy: 0.9642 - val_loss: 0.4736 - val_accuracy: 0.8685\n",
      "Epoch 107/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1102 - accuracy: 0.9628 - val_loss: 0.4679 - val_accuracy: 0.8702\n",
      "Epoch 108/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0992 - accuracy: 0.9673 - val_loss: 0.4762 - val_accuracy: 0.8760\n",
      "Epoch 109/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 0.4679 - val_accuracy: 0.8731\n",
      "Epoch 110/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1159 - accuracy: 0.9591 - val_loss: 0.4694 - val_accuracy: 0.8737\n",
      "Epoch 111/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1127 - accuracy: 0.9594 - val_loss: 0.4643 - val_accuracy: 0.8725\n",
      "Epoch 112/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1035 - accuracy: 0.9625 - val_loss: 0.5353 - val_accuracy: 0.8679\n",
      "Epoch 113/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1059 - accuracy: 0.9613 - val_loss: 0.4638 - val_accuracy: 0.8702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1027 - accuracy: 0.9639 - val_loss: 0.4785 - val_accuracy: 0.8697\n",
      "Epoch 115/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1078 - accuracy: 0.9636 - val_loss: 0.4893 - val_accuracy: 0.8622\n",
      "Epoch 116/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1147 - accuracy: 0.9616 - val_loss: 0.4491 - val_accuracy: 0.8743\n",
      "Epoch 117/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0987 - accuracy: 0.9645 - val_loss: 0.4598 - val_accuracy: 0.8806\n",
      "Epoch 118/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1195 - accuracy: 0.9565 - val_loss: 0.4583 - val_accuracy: 0.8749\n",
      "Epoch 119/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1067 - accuracy: 0.9650 - val_loss: 0.4797 - val_accuracy: 0.8749\n",
      "Epoch 120/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.4763 - val_accuracy: 0.8795\n",
      "Epoch 121/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1049 - accuracy: 0.9659 - val_loss: 0.4451 - val_accuracy: 0.8795\n",
      "Epoch 122/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0990 - accuracy: 0.9636 - val_loss: 0.4810 - val_accuracy: 0.8708\n",
      "Epoch 123/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0966 - accuracy: 0.9684 - val_loss: 0.4844 - val_accuracy: 0.8737\n",
      "Epoch 124/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0998 - accuracy: 0.9682 - val_loss: 0.4753 - val_accuracy: 0.8777\n",
      "Epoch 125/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 0.4837 - val_accuracy: 0.8760\n",
      "Epoch 126/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0877 - accuracy: 0.9690 - val_loss: 0.5050 - val_accuracy: 0.8679\n",
      "Epoch 127/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0909 - accuracy: 0.9713 - val_loss: 0.4831 - val_accuracy: 0.8708\n",
      "Epoch 128/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0884 - accuracy: 0.9676 - val_loss: 0.4834 - val_accuracy: 0.8679\n",
      "Epoch 129/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0948 - accuracy: 0.9667 - val_loss: 0.5343 - val_accuracy: 0.8668\n",
      "Epoch 130/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1007 - accuracy: 0.9628 - val_loss: 0.4842 - val_accuracy: 0.8679\n",
      "Epoch 131/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.4966 - val_accuracy: 0.8679\n",
      "Epoch 132/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0935 - accuracy: 0.9702 - val_loss: 0.4921 - val_accuracy: 0.8743\n",
      "Epoch 133/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.4640 - val_accuracy: 0.8766\n",
      "Epoch 134/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1079 - accuracy: 0.9642 - val_loss: 0.4797 - val_accuracy: 0.8708\n",
      "Epoch 135/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1029 - accuracy: 0.9673 - val_loss: 0.5012 - val_accuracy: 0.8731\n",
      "Epoch 136/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0813 - accuracy: 0.9730 - val_loss: 0.4715 - val_accuracy: 0.8737\n",
      "Epoch 137/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.5494 - val_accuracy: 0.8616\n",
      "Epoch 138/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1000 - accuracy: 0.9684 - val_loss: 0.4886 - val_accuracy: 0.8685\n",
      "Epoch 139/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1016 - accuracy: 0.9630 - val_loss: 0.5024 - val_accuracy: 0.8731\n",
      "Epoch 140/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0917 - accuracy: 0.9684 - val_loss: 0.4904 - val_accuracy: 0.8708\n",
      "Epoch 141/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0802 - accuracy: 0.9684 - val_loss: 0.4968 - val_accuracy: 0.8697\n",
      "Epoch 142/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0825 - accuracy: 0.9719 - val_loss: 0.4920 - val_accuracy: 0.8679\n",
      "Epoch 143/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0942 - accuracy: 0.9636 - val_loss: 0.4998 - val_accuracy: 0.8737\n",
      "Epoch 144/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0836 - accuracy: 0.9721 - val_loss: 0.5034 - val_accuracy: 0.8662\n",
      "Epoch 145/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0878 - accuracy: 0.9730 - val_loss: 0.5003 - val_accuracy: 0.8691\n",
      "Epoch 146/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0811 - accuracy: 0.9721 - val_loss: 0.5088 - val_accuracy: 0.8627\n",
      "Epoch 147/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0763 - accuracy: 0.9741 - val_loss: 0.5298 - val_accuracy: 0.8725\n",
      "Epoch 148/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0843 - accuracy: 0.9721 - val_loss: 0.5153 - val_accuracy: 0.8685\n",
      "Epoch 149/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1032 - accuracy: 0.9684 - val_loss: 0.5310 - val_accuracy: 0.8674\n",
      "Epoch 150/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0842 - accuracy: 0.9721 - val_loss: 0.4712 - val_accuracy: 0.8754\n",
      "Epoch 151/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0826 - accuracy: 0.9736 - val_loss: 0.4963 - val_accuracy: 0.8760\n",
      "Epoch 152/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0749 - accuracy: 0.9727 - val_loss: 0.4780 - val_accuracy: 0.8772\n",
      "Epoch 153/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0816 - accuracy: 0.9684 - val_loss: 0.5042 - val_accuracy: 0.8720\n",
      "Epoch 154/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0914 - accuracy: 0.9690 - val_loss: 0.4997 - val_accuracy: 0.8743\n",
      "Epoch 155/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0850 - accuracy: 0.9707 - val_loss: 0.5081 - val_accuracy: 0.8708\n",
      "Epoch 156/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0825 - accuracy: 0.9744 - val_loss: 0.4684 - val_accuracy: 0.8720\n",
      "Epoch 157/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0788 - accuracy: 0.9738 - val_loss: 0.5260 - val_accuracy: 0.8708\n",
      "Epoch 158/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0693 - accuracy: 0.9770 - val_loss: 0.5169 - val_accuracy: 0.8691\n",
      "Epoch 159/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0730 - accuracy: 0.9761 - val_loss: 0.5689 - val_accuracy: 0.8576\n",
      "Epoch 160/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0824 - accuracy: 0.9724 - val_loss: 0.5525 - val_accuracy: 0.8662\n",
      "Epoch 161/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0957 - accuracy: 0.9696 - val_loss: 0.5070 - val_accuracy: 0.8662\n",
      "Epoch 162/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 0.4728 - val_accuracy: 0.8720\n",
      "Epoch 163/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0842 - accuracy: 0.9702 - val_loss: 0.4718 - val_accuracy: 0.8789\n",
      "Epoch 164/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0765 - accuracy: 0.9747 - val_loss: 0.5289 - val_accuracy: 0.8737\n",
      "Epoch 165/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0952 - accuracy: 0.9721 - val_loss: 0.5102 - val_accuracy: 0.8743\n",
      "Epoch 166/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.0758 - accuracy: 0.9764 - val_loss: 0.5440 - val_accuracy: 0.8633\n",
      "Epoch 167/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.0707 - accuracy: 0.9787 - val_loss: 0.5344 - val_accuracy: 0.8697\n",
      "Epoch 168/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0758 - accuracy: 0.9756 - val_loss: 0.5455 - val_accuracy: 0.8725\n",
      "Epoch 169/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0776 - accuracy: 0.9741 - val_loss: 0.5163 - val_accuracy: 0.8783\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0890 - accuracy: 0.9719 - val_loss: 0.4994 - val_accuracy: 0.8789\n",
      "Epoch 171/200\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.0750 - accuracy: 0.9702 - val_loss: 0.4919 - val_accuracy: 0.8725\n",
      "Epoch 172/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.5042 - val_accuracy: 0.8720\n",
      "Epoch 173/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0810 - accuracy: 0.9710 - val_loss: 0.5142 - val_accuracy: 0.8679\n",
      "Epoch 174/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0719 - accuracy: 0.9770 - val_loss: 0.5031 - val_accuracy: 0.8766\n",
      "Epoch 175/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 0.5199 - val_accuracy: 0.8737\n",
      "Epoch 176/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 0.5218 - val_accuracy: 0.8720\n",
      "Epoch 177/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0772 - accuracy: 0.9721 - val_loss: 0.5283 - val_accuracy: 0.8720\n",
      "Epoch 178/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0744 - accuracy: 0.9738 - val_loss: 0.4947 - val_accuracy: 0.8760\n",
      "Epoch 179/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.4949 - val_accuracy: 0.8731\n",
      "Epoch 180/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 0.5555 - val_accuracy: 0.8725\n",
      "Epoch 181/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.4725 - val_accuracy: 0.8795\n",
      "Epoch 182/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0692 - accuracy: 0.9733 - val_loss: 0.5207 - val_accuracy: 0.8725\n",
      "Epoch 183/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0634 - accuracy: 0.9775 - val_loss: 0.5018 - val_accuracy: 0.8743\n",
      "Epoch 184/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0688 - accuracy: 0.9784 - val_loss: 0.5297 - val_accuracy: 0.8702\n",
      "Epoch 185/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0773 - accuracy: 0.9753 - val_loss: 0.5261 - val_accuracy: 0.8812\n",
      "Epoch 186/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.5657 - val_accuracy: 0.8674\n",
      "Epoch 187/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0751 - accuracy: 0.9738 - val_loss: 0.5732 - val_accuracy: 0.8668\n",
      "Epoch 188/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.5429 - val_accuracy: 0.8731\n",
      "Epoch 189/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0734 - accuracy: 0.9716 - val_loss: 0.5458 - val_accuracy: 0.8749\n",
      "Epoch 190/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0786 - accuracy: 0.9733 - val_loss: 0.5390 - val_accuracy: 0.8691\n",
      "Epoch 191/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.5627 - val_accuracy: 0.8725\n",
      "Epoch 192/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0758 - accuracy: 0.9719 - val_loss: 0.5418 - val_accuracy: 0.8766\n",
      "Epoch 193/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0736 - accuracy: 0.9758 - val_loss: 0.5498 - val_accuracy: 0.8702\n",
      "Epoch 194/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0658 - accuracy: 0.9741 - val_loss: 0.5172 - val_accuracy: 0.8725\n",
      "Epoch 195/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0729 - accuracy: 0.9767 - val_loss: 0.5280 - val_accuracy: 0.8806\n",
      "Epoch 196/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0679 - accuracy: 0.9747 - val_loss: 0.5070 - val_accuracy: 0.8749\n",
      "Epoch 197/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0722 - accuracy: 0.9724 - val_loss: 0.5770 - val_accuracy: 0.8708\n",
      "Epoch 198/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 0.5329 - val_accuracy: 0.8772\n",
      "Epoch 199/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0712 - accuracy: 0.9753 - val_loss: 0.5181 - val_accuracy: 0.8725\n",
      "Epoch 200/200\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0800 - accuracy: 0.9719 - val_loss: 0.5263 - val_accuracy: 0.8720\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92       189\n",
      "           1       0.71      0.87      0.78       123\n",
      "           2       0.84      0.87      0.85       263\n",
      "           3       0.88      0.83      0.86       254\n",
      "           4       0.93      0.91      0.92       262\n",
      "           5       0.86      0.90      0.88       243\n",
      "           6       0.87      0.88      0.88       209\n",
      "           7       0.90      0.83      0.86       191\n",
      "\n",
      "    accuracy                           0.87      1734\n",
      "   macro avg       0.87      0.87      0.87      1734\n",
      "weighted avg       0.88      0.87      0.87      1734\n",
      "\n",
      "[[167  13   2   4   0   1   1   1]\n",
      " [  2 107   5   1   0   2   6   0]\n",
      " [  0  15 228   1   4   5   4   6]\n",
      " [  3   6   9 212   3  18   1   2]\n",
      " [  2   2   5   5 238   3   4   3]\n",
      " [  0   2   5  13   2 218   1   2]\n",
      " [  1   5   6   2   7   0 184   4]\n",
      " [  1   0  12   2   2   6  10 158]]\n",
      "Saved trained model at D:\\InhouseProjects\\ESA\\model_training\\git\\audio-sentiment-analysis\\prototypes\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Trained_NN = train_neural_network(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at D:\\InhouseProjects\\ESA\\model_training\\git\\audio-sentiment-analysis\\prototypes\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "Trained_NN.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = Trained_NN.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aser_env",
   "language": "python",
   "name": "aser_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
